{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实验6 TensorFlow\n",
    "\n",
    "从本次实验开始，你将探索一个名为TensorFlow的DL框架，它使得构建NN更加容易，类似的框架还有 PaddlePaddle, Torch, Caffe, Keras 等。\n",
    "\n",
    "目标：使用TensorFlow 2.3进行如下操作\n",
    "* 使用 `tf.Variable` 来表示变量\n",
    "* 了解变量和常量的差别\n",
    "* 使用TensorFlow来加速DL编程开发\n",
    "* 在一个TensorFlow数据集上训练NN\n",
    "\n",
    "可以使用 `pip install tensorflow==2.3` 来下载安装指定版本的TensorFlow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<a name='1'></a>\n",
    "## 1 - 包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.framework.ops import EagerTensor\n",
    "from tensorflow.python.ops.resource_variable_ops import ResourceVariable\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<a name='1-1'></a>\n",
    "### 1.1 - 检查 TensorFlow 版本\n",
    "本次实验中使用的tensorflow版本为 v2.3，下面的代码将打印输出其版本号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<a name='2'></a>\n",
    "## 2 - 使用GradientTape进行基本的优化\n",
    "\n",
    "第二代TensorFlow的使用非常简洁. 仅需实现前向传播（TensorFlow将依据GradientTape中的记录信息自动计算梯度，并根据计算图进行反向传播），指定代价函数和优化器!\n",
    "\n",
    "类似Numpy中的arrays对象，在TensorFlow中使用`tf.Tensor`来表示多维数组\n",
    "\n",
    "下面，你将使用 `tf.Variable` 来存储你的变量，并在初始化时定义其形状和类型.\n",
    "通过 `tf.Variable` 的构造函数中的 `dtype` 参数可以指定变量的类型."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.0 - 数据集\n",
    "下面的代码将从HDF5文件读取实验要使用的 TensorFlow 数据集，这是一个手势数据集, 包含分辨率为64x64x3的图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_dataset = h5py.File('datasets/train_signs.h5', \"r\")\n",
    "test_dataset = h5py.File('datasets/test_signs.h5', \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train = tf.data.Dataset.from_tensor_slices(train_dataset['train_set_x'])\n",
    "y_train = tf.data.Dataset.from_tensor_slices(train_dataset['train_set_y'])\n",
    "\n",
    "x_test = tf.data.Dataset.from_tensor_slices(test_dataset['test_set_x'])\n",
    "y_test = tf.data.Dataset.from_tensor_slices(test_dataset['test_set_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.TensorSliceDataset"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "你可以通过for循环来访问tensorflow数据集中的数据, 或者使用`iter`来创建一个Python的迭代器，并通过`next`来访问下一个元素.\n",
    "你也可以通过`element_spec`属性来查看各个元素的`shape` 和 `dtype`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorSpec(shape=(), dtype=tf.int64, name=None)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[227 220 214]\n",
      "  [227 221 215]\n",
      "  [227 222 215]\n",
      "  ...\n",
      "  [232 230 224]\n",
      "  [231 229 222]\n",
      "  [230 229 221]]\n",
      "\n",
      " [[227 221 214]\n",
      "  [227 221 215]\n",
      "  [228 221 215]\n",
      "  ...\n",
      "  [232 230 224]\n",
      "  [231 229 222]\n",
      "  [231 229 221]]\n",
      "\n",
      " [[227 221 214]\n",
      "  [227 221 214]\n",
      "  [227 221 215]\n",
      "  ...\n",
      "  [232 230 224]\n",
      "  [231 229 223]\n",
      "  [230 229 221]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[119  81  51]\n",
      "  [124  85  55]\n",
      "  [127  87  58]\n",
      "  ...\n",
      "  [210 211 211]\n",
      "  [211 212 210]\n",
      "  [210 211 210]]\n",
      "\n",
      " [[119  79  51]\n",
      "  [124  84  55]\n",
      "  [126  85  56]\n",
      "  ...\n",
      "  [210 211 210]\n",
      "  [210 211 210]\n",
      "  [209 210 209]]\n",
      "\n",
      " [[119  81  51]\n",
      "  [123  83  55]\n",
      "  [122  82  54]\n",
      "  ...\n",
      "  [209 210 210]\n",
      "  [209 210 209]\n",
      "  [208 209 209]]], shape=(64, 64, 3), dtype=uint8)\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(x_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[227 220 214]\n",
      "  [227 221 215]\n",
      "  [227 222 215]\n",
      "  ...\n",
      "  [232 230 224]\n",
      "  [231 229 222]\n",
      "  [230 229 221]]\n",
      "\n",
      " [[227 221 214]\n",
      "  [227 221 215]\n",
      "  [228 221 215]\n",
      "  ...\n",
      "  [232 230 224]\n",
      "  [231 229 222]\n",
      "  [231 229 221]]\n",
      "\n",
      " [[227 221 214]\n",
      "  [227 221 214]\n",
      "  [227 221 215]\n",
      "  ...\n",
      "  [232 230 224]\n",
      "  [231 229 223]\n",
      "  [230 229 221]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[119  81  51]\n",
      "  [124  85  55]\n",
      "  [127  87  58]\n",
      "  ...\n",
      "  [210 211 211]\n",
      "  [211 212 210]\n",
      "  [210 211 210]]\n",
      "\n",
      " [[119  79  51]\n",
      "  [124  84  55]\n",
      "  [126  85  56]\n",
      "  ...\n",
      "  [210 211 210]\n",
      "  [210 211 210]\n",
      "  [209 210 209]]\n",
      "\n",
      " [[119  81  51]\n",
      "  [123  83  55]\n",
      "  [122  82  54]\n",
      "  ...\n",
      "  [209 210 210]\n",
      "  [209 210 209]\n",
      "  [208 209 209]]], shape=(64, 64, 3), dtype=uint8)\n"
     ]
    }
   ],
   "source": [
    "for element in x_train:\n",
    "    print(element)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "如果要对TensorFlow数据集进行转换，需要使用 `map` 方法（如下所示）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function：\n",
    "    Transform an image into a tensor of shape (64 * 64 * 3, 1)\n",
    "    and normalize its components.\n",
    "Arguments：\n",
    "    image - Tensor.\n",
    "Returns:\n",
    "    result -- Transformed tensor\n",
    "\"\"\"\n",
    "def normalize(image):\n",
    "    image = tf.cast(image, tf.float32) / 256.0\n",
    "    image = tf.reshape(image, [-1,1])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_train = x_train.map(normalize)\n",
    "new_test = x_test.map(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorSpec(shape=(12288, 1), dtype=tf.float32, name=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.88671875]\n",
      " [0.859375  ]\n",
      " [0.8359375 ]\n",
      " ...\n",
      " [0.8125    ]\n",
      " [0.81640625]\n",
      " [0.81640625]], shape=(12288, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(new_train)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<a name='2-1'></a>\n",
    "### 2.1 - 线性函数\n",
    "\n",
    "让我们计算: $Y = WX + b$, 其中 $W$ 和 $X$ 是随机矩阵，b 是一个随机向量\n",
    "\n",
    "<a name='ex-1'></a>\n",
    "#### 练习 1 - linear_function\n",
    "\n",
    "计算 $WX + b$，其中 $W, X$, 和 $b$ 的元素值是服从正态分布的随机数. W 的形状为 (4, 3), X 为 (3,1)，b 为 (4,1).\n",
    "\n",
    "*提示*:\n",
    "- 下面的代码可以定义一个形状为(3,1)的常量X:\n",
    "```python\n",
    "X = tf.constant(np.random.randn(3,1))\n",
    "```\n",
    "`tf.constant` 和 `tf.Variable` 的区别在于：你可以改变一个`tf.Variable`的值，`tf.constant`则不行.\n",
    "- tf.matmul(..., ...) 可以用来进行矩阵相乘\n",
    "- tf.add(..., ...) 可以用来做加法\n",
    "- np.random.randn(...) 可以用来随机初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function：\n",
    "    Implements a linear function:\n",
    "        Initializes X to be a random tensor of shape (3,1)\n",
    "        Initializes W to be a random tensor of shape (4,3)\n",
    "        Initializes b to be a random tensor of shape (4,1)\n",
    "Returns:\n",
    "    result -- Y = WX + b\n",
    "\"\"\"\n",
    "def linear_function():\n",
    "    np.random.seed(1)\n",
    "    \"\"\"\n",
    "    Note, to ensure that the \"random\" numbers generated match the expected results,\n",
    "    please create the variables in the order given in the starting code below.\n",
    "    (Do not re-arrange the order).\n",
    "    \"\"\"\n",
    "    # (approx. 4 lines)\n",
    "    # X = ...\n",
    "    # W = ...\n",
    "    # b = ...\n",
    "    # Y = ...\n",
    "    # YOUR CODE STARTS HERE\n",
    "    X = tf.constant(np.random.randn(3,1), name = \"X\")\n",
    "    W = tf.Variable(np.random.randn(4,3), name = \"X\")\n",
    "    b = tf.Variable(np.random.randn(4,1), name = \"X\")\n",
    "    Y = W@X + b \n",
    "    # YOUR CODE ENDS HERE\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-2.15657382]\n",
      " [ 2.95891446]\n",
      " [-1.08926781]\n",
      " [-0.84538042]], shape=(4, 1), dtype=float64)\n",
      "\u001b[92mAll test passed\n"
     ]
    }
   ],
   "source": [
    "result = linear_function()\n",
    "print(result)\n",
    "\n",
    "assert type(result) == EagerTensor, \"Use the TensorFlow API\"\n",
    "assert np.allclose(result, [[-2.15657382], [ 2.95891446], [-1.08926781], [-0.84538042]]), \"Error\"\n",
    "print(\"\\033[92mAll test passed\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<a name='2-2'></a>\n",
    "### 2.2 - 计算Sigmoid\n",
    "TensorFlow 提供了NN中各种各样会用到的函数，例如`tf.sigmoid` 和 `tf.softmax`.\n",
    "接下来你将实现计算z的sigmoid值，首先需要使用`tf.cast`将你的张量转换为`float32` 类型 , 然后调用 `tf.keras.activations.sigmoid`完成计算.\n",
    "\n",
    "<a name='ex-2'></a>\n",
    "#### 练习 2 - sigmoid\n",
    "\n",
    "通过2步实现sigmoid函数:\n",
    "1. 数据转换 `tf.cast(\"...\", tf.float32)`\n",
    "2. 函数调用 `tf.keras.activations.sigmoid(\"...\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function：\n",
    "    Computes the sigmoid of z\n",
    "Arguments:\n",
    "    z -- input value, scalar or vector\n",
    "Returns:\n",
    "    a -- (tf.float32) the sigmoid of z\n",
    "\"\"\"\n",
    "def sigmoid(z):\n",
    "    # tf.keras.activations.sigmoid requires float16, float32, float64, complex64, or complex128.\n",
    "    # (approx. 2 lines)\n",
    "    # z = ...\n",
    "    # a = ...\n",
    "    # YOUR CODE STARTS HERE\n",
    "    z = tf.cast(z, tf.float32)\n",
    "    a = tf.keras.activations.sigmoid(z)\n",
    "    # YOUR CODE ENDS HERE\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "dtype: <dtype: 'float32'>\n",
      "sigmoid(-1) = tf.Tensor(0.26894143, shape=(), dtype=float32)\n",
      "sigmoid(0) = tf.Tensor(0.5, shape=(), dtype=float32)\n",
      "sigmoid(12) = tf.Tensor(0.9999939, shape=(), dtype=float32)\n",
      "\u001b[92mAll test passed\n"
     ]
    }
   ],
   "source": [
    "result = sigmoid(-1)\n",
    "print (\"type: \" + str(type(result)))\n",
    "print (\"dtype: \" + str(result.dtype))\n",
    "print (\"sigmoid(-1) = \" + str(result))\n",
    "print (\"sigmoid(0) = \" + str(sigmoid(0.0)))\n",
    "print (\"sigmoid(12) = \" + str(sigmoid(12)))\n",
    "\n",
    "def sigmoid_test(target):\n",
    "    result = target(0)\n",
    "    assert(type(result) == EagerTensor)\n",
    "    assert (result.dtype == tf.float32)\n",
    "    assert sigmoid(0) == 0.5, \"Error\"\n",
    "    assert sigmoid(-1) == 0.26894143, \"Error\"\n",
    "    assert sigmoid(12) == 0.9999939, \"Error\"\n",
    "\n",
    "    print(\"\\033[92mAll test passed\")\n",
    "\n",
    "sigmoid_test(sigmoid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<a name='2-3'></a>\n",
    "### 2.3 - 使用 One Hot 编码\n",
    "\n",
    "在之前的分类例子中，多个样本的标签$Y$通常被表示为一个取值$0$ 到 $C-1$的向量（$C$为类别数）。下图展示了将一个类别数为4的$Y$转换为名为\"one hot\"编码数据的结果。\n",
    "\n",
    "<img src=\"images/onehot.png\" width=1000>\n",
    "\n",
    "要在numpy中实现该编码需要较多的代码，在TensorFlow则仅需一行代码:\n",
    "\n",
    "- [tf.one_hot(labels, depth, axis=0)](https://www.tensorflow.org/api_docs/python/tf/one_hot)\n",
    "\n",
    "当`axis=0`时，其输出数据的尺寸为 depth * len(labels)\n",
    "\n",
    "<a name='ex-3'></a>\n",
    "#### 练习 3 - one_hot_matrix\n",
    "\n",
    "实现一个函数，其参数为一个标签和类别数$C$，返回列式的one hot编码矩阵（仅有1列）.\n",
    "*提示*：\n",
    "- 使用`tf.one_hot()`进行one hot编码\n",
    "- 使用`tf.reshape(tensor, shape)` 改变矩阵形状!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function：\n",
    "    Computes the one hot encoding for a single label\n",
    "Arguments:\n",
    "    label --  (int) Categorical labels\n",
    "    depth --  (int) Number of different classes that label can take\n",
    "Returns:\n",
    "    one_hot -- (tf.Tensor) A single-column matrix with the one hot encoding.\n",
    "\"\"\"\n",
    "def one_hot_matrix(label, depth=6):\n",
    "    # (approx. 1 line)\n",
    "    # one_hot = ...\n",
    "    # YOUR CODE STARTS HERE\n",
    "    one_hot = tf.reshape(tf.one_hot(label, depth, axis=0), [depth,1])\n",
    "    # YOUR CODE ENDS HERE\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]], shape=(4, 1), dtype=float32)\n",
      "\u001b[92mAll test passed\n"
     ]
    }
   ],
   "source": [
    "def one_hot_matrix_test(target):\n",
    "    label = tf.constant(1)\n",
    "    depth = 4\n",
    "    result = target(label, depth)\n",
    "    print(result)\n",
    "    assert result.shape[0] == depth, \"Use the parameter depth\"\n",
    "    assert result.shape[1] == 1, f\"Reshape to have only 1 column\"\n",
    "    assert np.allclose(result,  [[0.], [1.], [0.], [0.]] ), \"Wrong output. Use tf.one_hot\"\n",
    "    result = target(3, depth)\n",
    "    assert np.allclose(result, [[0.], [0.], [0.], [1.]] ), \"Wrong output. Use tf.one_hot\"\n",
    "\n",
    "    print(\"\\033[92mAll test passed\")\n",
    "\n",
    "one_hot_matrix_test(one_hot_matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "查看转换后的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y_test = y_test.map(one_hot_matrix)\n",
    "new_y_train = y_train.map(one_hot_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]], shape=(6, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(new_y_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2-4'></a>\n",
    "### 2.4 - 参数初始化\n",
    "\n",
    "你将初始化一个取值[0,1]的向量，所调用的函数为 `tf.keras.initializers.GlorotNormal`, 其生成的随机数服从均值为0、标准差`stddev = sqrt(2 / (fan_in + fan_out))`的截断的正态分布，其中 `fan_in` 和 `fan_out` 分别表示输入、输出单元的个数\n",
    "\n",
    "全0或全1初始化可使用 `tf.zeros()` or `tf.ones()`.\n",
    "\n",
    "<a name='ex-4'></a>\n",
    "#### 练习 4 - initialize_parameters\n",
    "\n",
    "实现下面的函数，其输入参数为形状shape，返回值为取值[-1,1]之间的数组.步骤包括：\n",
    "- `tf.keras.initializers.GlorotNormal(seed=1)`\n",
    "- `tf.Variable(initializer(shape=())`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "da48416c74797c83152e1080b08afb9d",
     "grade": false,
     "grade_id": "cell-1d5716c48a16debf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function：\n",
    "    Initializes parameters to build a neural network with TensorFlow. The shapes are:\n",
    "        W1 : [25, 12288]\n",
    "        b1 : [25, 1]\n",
    "        W2 : [12, 25]\n",
    "        b2 : [12, 1]\n",
    "        W3 : [6, 12]\n",
    "        b3 : [6, 1]\n",
    "Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, b1, W2, b2, W3, b3\n",
    "\"\"\"\n",
    "def initialize_parameters():\n",
    "    initializer = tf.keras.initializers.GlorotNormal(seed=1)   \n",
    "    #(approx. 6 lines of code)\n",
    "    # W1 = ...\n",
    "    # b1 = ...\n",
    "    # W2 = ...\n",
    "    # b2 = ...\n",
    "    # W3 = ...\n",
    "    # b3 = ...\n",
    "    # YOUR CODE STARTS HERE\n",
    "    W1 = tf.Variable(initializer(shape=([25, 12288])))\n",
    "    b1 = tf.Variable(initializer(shape=([25, 1])))\n",
    "    W2 = tf.Variable(initializer(shape=([12, 25])))\n",
    "    b2 = tf.Variable(initializer(shape=([12, 1])))\n",
    "    W3 = tf.Variable(initializer(shape=([6, 12])))\n",
    "    b3 = tf.Variable(initializer(shape=([6, 1])))\n",
    "    # YOUR CODE ENDS HERE\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dd3fe0b5ed777771156c071d9373e47a",
     "grade": true,
     "grade_id": "cell-11012e1fada40919",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 shape: (25, 12288)\n",
      "b1 shape: (25, 1)\n",
      "W2 shape: (12, 25)\n",
      "b2 shape: (12, 1)\n",
      "W3 shape: (6, 12)\n",
      "b3 shape: (6, 1)\n",
      "\u001b[92mAll test passed\n"
     ]
    }
   ],
   "source": [
    "def initialize_parameters_test(target):\n",
    "    parameters = target()\n",
    "\n",
    "    values = {\"W1\": (25, 12288),\n",
    "              \"b1\": (25, 1),\n",
    "              \"W2\": (12, 25),\n",
    "              \"b2\": (12, 1),\n",
    "              \"W3\": (6, 12),\n",
    "              \"b3\": (6, 1)}\n",
    "\n",
    "    for key in parameters:\n",
    "        print(f\"{key} shape: {tuple(parameters[key].shape)}\")\n",
    "        assert type(parameters[key]) == ResourceVariable, \"All parameter must be created using tf.Variable\"\n",
    "        assert tuple(parameters[key].shape) == values[key], f\"{key}: wrong shape\"\n",
    "        assert np.abs(np.mean(parameters[key].numpy())) < 0.5,  f\"{key}: Use the GlorotNormal initializer\"\n",
    "        assert np.std(parameters[key].numpy()) > 0 and np.std(parameters[key].numpy()) < 1, f\"{key}: Use the GlorotNormal initializer\"\n",
    "\n",
    "    print(\"\\033[92mAll test passed\")\n",
    "    \n",
    "initialize_parameters_test(initialize_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = initialize_parameters()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## 3 - 使用TensorFlow构建你的第一个NN\n",
    "\n",
    "需要做两部分工作：\n",
    "- 实现前向传播\n",
    "- 检索得到梯度并训练模型"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3-1'></a>\n",
    "### 3.1 - 实现前向传播\n",
    "\n",
    "你将使用 `@tf.function`, 它将构建一个计算图，以便计算梯度用于反向传播.\n",
    "\n",
    "<a name='ex-5'></a>\n",
    "#### 练习 5 - forward_propagation\n",
    "\n",
    "实现 `forward_propagation` 函数.\n",
    "\n",
    "**注意**\n",
    "仅使用TF的API接口，包括：\n",
    "- tf.math.add\n",
    "- tf.linalg.matmul\n",
    "- tf.keras.activations.relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7c3d7c28e47e314c17d3f35e5a033b15",
     "grade": false,
     "grade_id": "cell-23b6d82b3443e298",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function：\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR\n",
    "Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "\"\"\"\n",
    "@tf.function\n",
    "def forward_propagation(X, parameters):\n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    #(approx. 5 lines)                   # Numpy Equivalents:\n",
    "    # Z1 = ...                           # Z1 = np.dot(W1, X) + b1\n",
    "    # A1 = ...                           # A1 = relu(Z1)\n",
    "    # Z2 = ...                           # Z2 = np.dot(W2, A1) + b2\n",
    "    # A2 = ...                           # A2 = relu(Z2)\n",
    "    # Z3 = ...                           # Z3 = np.dot(W3, A2) + b3\n",
    "    # YOUR CODE STARTS HERE\n",
    "    Z1 = tf.math.add(tf.linalg.matmul(W1,X), b1)                          \n",
    "    A1 = tf.keras.activations.relu(Z1)                                     \n",
    "    Z2 = tf.math.add(tf.linalg.matmul(W2,A1), b2)                                   \n",
    "    A2 = tf.keras.activations.relu(Z2)                                       \n",
    "    Z3 = tf.math.add(tf.linalg.matmul(W3,A2), b3)\n",
    "    # YOUR CODE ENDS HERE\n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "204b6a74e3c6cbdb3654bdb2ed8f13af",
     "grade": true,
     "grade_id": "cell-728b002a6a88ceb1",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function forward_propagation at 0x0000026058B22A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function forward_propagation at 0x0000026058B22A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "tf.Tensor(\n",
      "[[-0.13082099]\n",
      " [ 0.21228725]\n",
      " [ 0.7050022 ]\n",
      " [-1.1224037 ]\n",
      " [-0.2038675 ]\n",
      " [ 0.95262194]], shape=(6, 1), dtype=float32)\n",
      "\u001b[92mAll test passed\n"
     ]
    }
   ],
   "source": [
    "def forward_propagation_test(target, examples):\n",
    "    for batch in examples:\n",
    "        forward_pass = target(batch, parameters)\n",
    "        assert type(forward_pass) == EagerTensor, \"Your output is not a tensor\"\n",
    "        assert forward_pass.shape == (6, 1), \"Last layer must use W3 and b3\"\n",
    "        assert np.any(forward_pass < 0), \"Don't use a ReLu layer at end of your network\"\n",
    "        assert np.allclose(forward_pass, \n",
    "                           [[-0.13082162],\n",
    "                           [ 0.21228778],\n",
    "                           [ 0.7050022 ],\n",
    "                           [-1.1224034 ],\n",
    "                           [-0.20386729],\n",
    "                           [ 0.9526217 ]]), \"Output does not match\"\n",
    "        print(forward_pass)\n",
    "        break\n",
    "    \n",
    "\n",
    "    print(\"\\033[92mAll test passed\")\n",
    "\n",
    "forward_propagation_test(forward_propagation, new_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3-2'></a>\n",
    "### 3.2 计算代价\n",
    "\n",
    "下面的代码展示了计算代价函数的一种方式\n",
    "\n",
    "`tf.reduce_mean(tf.keras.losses.binary_crossentropy(y_true = ..., y_pred = ..., from_logits=True))`\n",
    "\n",
    "<a name='ex-6'></a>\n",
    "#### 练习 6 -  compute_cost\n",
    "\n",
    "实现下面的代价函数\n",
    "- 需要特别注意的是[tf.keras.losses.binary_crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/binary_crossentropy) 的输入\"`y_pred`\" 和 \"`y_true`\"，其形状应该是 (number of examples, num_classes).\n",
    "- `tf.reduce_mean` 用于计算tensor沿着指定的数轴上的平均值."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "af252bad785c3ddf4a55fa7bc999477a",
     "grade": false,
     "grade_id": "cell-e6cc4d7fefeed231",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function：\n",
    "    Computes the cost\n",
    "Arguments:\n",
    "    logits -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)\n",
    "    labels -- \"true\" labels vector, same shape as Z3\n",
    "Returns:\n",
    "    cost - Tensor of the cost function\n",
    "\"\"\"\n",
    "@tf.function\n",
    "def compute_cost(logits, labels):\n",
    "    #(1 line of code)\n",
    "    # cost = ...\n",
    "    # YOUR CODE STARTS HERE\n",
    "    cost = tf.reduce_mean(tf.keras.losses.binary_crossentropy(y_true = labels, y_pred = logits, from_logits=True))\n",
    "    # YOUR CODE ENDS HERE\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "938580c5cbcf49a72c1fdcda782cfd8a",
     "grade": true,
     "grade_id": "cell-9bf72affa2e7b1b5",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.8419182681095858, shape=(), dtype=float64)\n",
      "\u001b[92mAll test passed\n"
     ]
    }
   ],
   "source": [
    "def compute_cost_test(target):\n",
    "    labels = np.array([[0., 1.], [0., 0.], [1., 0.]])\n",
    "    logits = np.array([[0.6, 0.4], [0.4, 0.6], [0.4, 0.6]])\n",
    "    result = compute_cost(logits, labels)\n",
    "    print(result)\n",
    "    assert(type(result) == EagerTensor), \"Use the TensorFlow API\"\n",
    "    assert (np.abs(result - (0.7752516 +  0.9752516 + 0.7752516) / 3.0) < 1e-7), \"Test does not match. Did you get the mean of your cost functions?\"\n",
    "\n",
    "    print(\"\\033[92mAll test passed\")\n",
    "\n",
    "compute_cost_test(compute_cost)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3-3'></a>\n",
    "### 3.3 - 训练模型\n",
    "\n",
    "Let's talk optimizers. You'll specify the type of optimizer in one line, in this case `tf.keras.optimizers.Adam` (though you can use others such as SGD), and then call it within the training loop. \n",
    "\n",
    "Notice the `tape.gradient` function: this allows you to retrieve the operations recorded for automatic differentiation inside the `GradientTape` block. Then, calling the optimizer method `apply_gradients`, will apply the optimizer's update rules to each trainable parameter. At the end of this assignment, you'll find some documentation that explains this more in detail, but for now, a simple explanation will do. ;) \n",
    "\n",
    "\n",
    "Here you should take note of an important extra step that's been added to the batch training process: \n",
    "\n",
    "- `tf.Data.dataset = dataset.prefetch(8)` \n",
    "\n",
    "What this does is prevent a memory bottleneck that can occur when reading from disk. `prefetch()` sets aside some data and keeps it ready for when it's needed. It does this by creating a source dataset from your input data, applying a transformation to preprocess the data, then iterating over the dataset the specified number of elements at a time. This works because the iteration is streaming, so the data doesn't need to fit into the memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function:\n",
    "    Implements a three-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n",
    "Arguments:\n",
    "    X_train -- training set, of shape (input size = 12288, number of training examples = 1080)\n",
    "    Y_train -- test set, of shape (output size = 6, number of training examples = 1080)\n",
    "    X_test -- training set, of shape (input size = 12288, number of training examples = 120)\n",
    "    Y_test -- test set, of shape (output size = 6, number of test examples = 120)\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "\"\"\"\n",
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n",
    "          num_epochs = 1500, minibatch_size = 32, print_cost = True):\n",
    "    costs = []     # To keep track of the cost\n",
    "    # Initialize your parameters\n",
    "    #(1 line)\n",
    "    parameters = initialize_parameters()\n",
    "\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
    "\n",
    "    X_train = X_train.batch(minibatch_size, drop_remainder=True).prefetch(8)# <<< extra step    \n",
    "    Y_train = Y_train.batch(minibatch_size, drop_remainder=True).prefetch(8) # loads memory faster \n",
    "\n",
    "    # Do the training loop\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        epoch_cost = 0.\n",
    "        \n",
    "        for (minibatch_X, minibatch_Y) in zip(X_train, Y_train):\n",
    "            # Select a minibatch\n",
    "            with tf.GradientTape() as tape:\n",
    "                # 1. predict\n",
    "                Z3 = forward_propagation(minibatch_X, parameters)\n",
    "                # 2. loss\n",
    "                minibatch_cost = compute_cost(Z3, minibatch_Y)\n",
    "                \n",
    "            trainable_variables = [W1, b1, W2, b2, W3, b3]\n",
    "            grads = tape.gradient(minibatch_cost, trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, trainable_variables))\n",
    "            epoch_cost += minibatch_cost / minibatch_size\n",
    "\n",
    "        # Print the cost every epoch\n",
    "        if print_cost == True and epoch % 10 == 0:\n",
    "            print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "        if print_cost == True and epoch % 5 == 0:\n",
    "            costs.append(epoch_cost)\n",
    "\n",
    "    # Plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per fives)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "\n",
    "    # Save the parameters in a variable\n",
    "    print (\"Parameters have been trained!\")\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.742591\n",
      "Cost after epoch 10: 0.614557\n",
      "Cost after epoch 20: 0.598900\n",
      "Cost after epoch 30: 0.588907\n",
      "Cost after epoch 40: 0.579898\n",
      "Cost after epoch 50: 0.570628\n",
      "Cost after epoch 60: 0.560898\n",
      "Cost after epoch 70: 0.550808\n",
      "Cost after epoch 80: 0.540497\n",
      "Cost after epoch 90: 0.488141\n",
      "Cost after epoch 100: 0.478272\n",
      "Cost after epoch 110: 0.472865\n",
      "Cost after epoch 120: 0.468991\n",
      "Cost after epoch 130: 0.466015\n",
      "Cost after epoch 140: 0.463661\n",
      "Cost after epoch 150: 0.461677\n",
      "Cost after epoch 160: 0.459951\n",
      "Cost after epoch 170: 0.458392\n",
      "Cost after epoch 180: 0.456970\n",
      "Cost after epoch 190: 0.455646\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'W1': <tf.Variable 'Variable:0' shape=(25, 12288) dtype=float32, numpy=\n",
       " array([[ 0.00159524, -0.00737916,  0.00893293, ..., -0.01227792,\n",
       "          0.01642205,  0.00506485],\n",
       "        [ 0.02264025,  0.0067227 ,  0.00795862, ...,  0.00284724,\n",
       "          0.01910819,  0.00122853],\n",
       "        [-0.0017358 , -0.00872449, -0.01410439, ..., -0.00733832,\n",
       "          0.02050859, -0.02683017],\n",
       "        ...,\n",
       "        [-0.00126929,  0.01729332,  0.02082342, ...,  0.01709594,\n",
       "          0.00429358, -0.00733263],\n",
       "        [ 0.00268265,  0.00410502,  0.00936712, ...,  0.01222286,\n",
       "         -0.02717603,  0.01498357],\n",
       "        [-0.00145541,  0.02459595,  0.00339064, ..., -0.02478788,\n",
       "          0.02716016, -0.00306428]], dtype=float32)>,\n",
       " 'b1': <tf.Variable 'Variable:0' shape=(25, 1) dtype=float32, numpy=\n",
       " array([[ 0.03964259],\n",
       "        [-0.15545043],\n",
       "        [ 0.19885877],\n",
       "        [-0.24874453],\n",
       "        [-0.28676733],\n",
       "        [-0.12604602],\n",
       "        [-0.01213097],\n",
       "        [ 0.14784054],\n",
       "        [-0.00413176],\n",
       "        [-0.4408978 ],\n",
       "        [ 0.5405421 ],\n",
       "        [-0.4345032 ],\n",
       "        [ 0.11763887],\n",
       "        [ 0.21523887],\n",
       "        [-0.06772608],\n",
       "        [-0.1642928 ],\n",
       "        [-0.0525962 ],\n",
       "        [-0.184795  ],\n",
       "        [-0.00280256],\n",
       "        [-0.06777475],\n",
       "        [ 0.09226809],\n",
       "        [ 0.02067652],\n",
       "        [-0.05682073],\n",
       "        [ 0.37065938],\n",
       "        [ 0.21586621]], dtype=float32)>,\n",
       " 'W2': <tf.Variable 'Variable:0' shape=(12, 25) dtype=float32, numpy=\n",
       " array([[ 0.03270398, -0.13031   ,  0.16566682, -0.20850259, -0.2404858 ,\n",
       "         -0.10598166, -0.01016674,  0.12317107, -0.00411659, -0.3709333 ,\n",
       "          0.45312327, -0.36423257,  0.09766971,  0.18042907, -0.05753208,\n",
       "         -0.13796303, -0.04518652, -0.15597364, -0.00236228, -0.05681378,\n",
       "          0.07734591,  0.01733258, -0.04763132,  0.31054643,  0.18095495],\n",
       "        [ 0.2750061 ,  0.0652916 ,  0.1927715 ,  0.00808901, -0.35061082,\n",
       "         -0.04379591,  0.00529772,  0.14074577, -0.22700588, -0.08254343,\n",
       "         -0.10437229, -0.27877635, -0.22737703, -0.15467171, -0.30434495,\n",
       "          0.4284151 ,  0.04013151,  0.14082794,  0.40803385,  0.19127996,\n",
       "         -0.08289494,  0.19833343, -0.18854785,  0.11045358, -0.10293514],\n",
       "        [ 0.07370563,  0.12879197, -0.3804876 , -0.1428371 , -0.16866723,\n",
       "         -0.12560502,  0.08047906, -0.14222318, -0.32914382,  0.11487077,\n",
       "          0.21897395,  0.1428981 ,  0.41085437, -0.02966296, -0.11487778,\n",
       "          0.2835232 ,  0.2571578 , -0.12365901,  0.14695017, -0.39992067,\n",
       "         -0.11544652, -0.11918075, -0.5031594 , -0.16646984, -0.0463655 ],\n",
       "        [-0.11886355,  0.19529893, -0.1320524 , -0.46206364,  0.07806107,\n",
       "         -0.36992034, -0.06379854,  0.37158272,  0.07555988,  0.5198789 ,\n",
       "         -0.01714149,  0.35476214,  0.09361269,  0.17954443,  0.00514449,\n",
       "          0.04280839,  0.10517986,  0.03766977, -0.23309667, -0.23678231,\n",
       "         -0.07444265, -0.30713868, -0.11694647,  0.3292593 , -0.09511968],\n",
       "        [ 0.15940411,  0.0393942 ,  0.47869274,  0.2265753 ,  0.03725043,\n",
       "         -0.51921755, -0.0173153 , -0.3157803 , -0.2167203 ,  0.0412293 ,\n",
       "          0.04947526, -0.29094276, -0.03152777,  0.47902155,  0.3167656 ,\n",
       "          0.04739   ,  0.07770435,  0.31394583, -0.02500664,  0.10048122,\n",
       "         -0.05332499, -0.34107792, -0.13928485,  0.12402104, -0.41300818],\n",
       "        [-0.14994687,  0.03965309, -0.47870174, -0.07975383,  0.09755065,\n",
       "         -0.00232861, -0.26367775, -0.23967458,  0.24946521,  0.22969176,\n",
       "         -0.30773667,  0.1017215 ,  0.0305302 ,  0.26468748, -0.51858556,\n",
       "         -0.08669734,  0.03128887,  0.28504825,  0.20724739, -0.14461054,\n",
       "         -0.09631125,  0.2553377 ,  0.0313108 ,  0.2868451 ,  0.02228327],\n",
       "        [-0.20329641, -0.2922766 , -0.03024991,  0.00603078,  0.34428513,\n",
       "          0.14932795, -0.42723438,  0.07875892,  0.06157893, -0.19437575,\n",
       "          0.03054013, -0.20949648,  0.2890019 ,  0.03168807,  0.18291236,\n",
       "         -0.17629069, -0.2162296 ,  0.02522451, -0.17976451,  0.20999093,\n",
       "          0.13074148,  0.12900151, -0.29620144,  0.39828372,  0.35581756],\n",
       "        [-0.08132942,  0.0508789 ,  0.03970909, -0.06884057, -0.07758211,\n",
       "          0.21220328,  0.16169944, -0.05766107, -0.04837854, -0.23052695,\n",
       "          0.2551639 , -0.2933403 , -0.16104451, -0.11232601, -0.1305835 ,\n",
       "          0.0502181 ,  0.18621859, -0.07786819,  0.10281896, -0.06372993,\n",
       "          0.41251048, -0.01803587,  0.04746069,  0.27628538, -0.21901166],\n",
       "        [ 0.28539085,  0.20629272, -0.3837217 ,  0.26297212,  0.23504943,\n",
       "          0.18105377,  0.25501856, -0.19114947,  0.35580727,  0.00106983,\n",
       "         -0.33252382, -0.09722907, -0.00984808,  0.22310142, -0.22939903,\n",
       "         -0.02731943,  0.1857264 , -0.00867903,  0.47467554,  0.00131025,\n",
       "          0.3148377 , -0.22662118,  0.12927507,  0.0426539 , -0.45121887],\n",
       "        [-0.23054187, -0.22334962, -0.18913192,  0.15417175, -0.07368277,\n",
       "         -0.0554374 ,  0.12214173,  0.3880139 , -0.01242276,  0.11768965,\n",
       "          0.26777858, -0.06251994, -0.12100054, -0.12495217, -0.03189994,\n",
       "         -0.50085783, -0.09560107, -0.2402923 ,  0.07087833,  0.03642716,\n",
       "         -0.00494978, -0.36984688,  0.00878784,  0.24595837, -0.1323934 ],\n",
       "        [ 0.31912857,  0.02266271, -0.06669842, -0.33996752,  0.36436084,\n",
       "         -0.29865557, -0.05117008, -0.37243617,  0.27359548,  0.20692156,\n",
       "          0.02171064,  0.10230298, -0.39800125,  0.02363082,  0.13089404,\n",
       "          0.33540627,  0.08214819,  0.20031588, -0.08127794, -0.28784147,\n",
       "          0.17327178, -0.1326688 ,  0.28894275, -0.1986986 , -0.03405774],\n",
       "        [ 0.1882051 , -0.20398362, -0.03503598, -0.36792815, -0.22963934,\n",
       "          0.23911734, -0.04237935, -0.01655166, -0.05906219,  0.16423771,\n",
       "         -0.32017097,  0.15379827,  0.14842783, -0.24647985, -0.08833598,\n",
       "          0.13306317,  0.41101137,  0.36263096,  0.33551395,  0.05405051,\n",
       "          0.21186371,  0.0197499 ,  0.45979315,  0.04402933,  0.36662805]],\n",
       "       dtype=float32)>,\n",
       " 'b2': <tf.Variable 'Variable:0' shape=(12, 1) dtype=float32, numpy=\n",
       " array([[ 0.05586328],\n",
       "        [-0.22080162],\n",
       "        [ 0.28016457],\n",
       "        [-0.35078046],\n",
       "        [-0.407107  ],\n",
       "        [-0.17678554],\n",
       "        [-0.01738933],\n",
       "        [ 0.20840582],\n",
       "        [-0.00978931],\n",
       "        [-0.6255955 ],\n",
       "        [ 0.76646936],\n",
       "        [-0.61273056]], dtype=float32)>,\n",
       " 'W3': <tf.Variable 'Variable:0' shape=(6, 12) dtype=float32, numpy=\n",
       " array([[ 0.04761663, -0.18691434,  0.23871906, -0.29910973, -0.34814334,\n",
       "         -0.14891644, -0.01468904,  0.17718893, -0.00528845, -0.53165394,\n",
       "          0.6512269 , -0.5256208 ],\n",
       "        [ 0.14137168,  0.2585655 , -0.08242739, -0.24897751, -0.08694404,\n",
       "         -0.23124084, -0.00362752, -0.08165746,  0.10867117,  0.02485008,\n",
       "         -0.10594471,  0.4071276 ],\n",
       "        [ 0.2588232 ,  0.3953151 ,  0.09260609,  0.19811353, -0.02675309,\n",
       "         -0.51413274, -0.06277467,  0.0073774 ,  0.20107777, -0.3234572 ,\n",
       "         -0.17168547, -0.21085018],\n",
       "        [-0.39999744, -0.32459357, -0.22211896, -0.44647512,  0.60610944,\n",
       "          0.06233899,  0.20539553,  0.5849541 ,  0.27438086, -0.11884821,\n",
       "          0.27649114, -0.28224474],\n",
       "        [ 0.15867612, -0.14753199,  0.10718004,  0.20221263, -0.53973365,\n",
       "         -0.19613925, -0.24190293, -0.17912963,  0.11743037, -0.20150405,\n",
       "         -0.4571613 ,  0.17953788],\n",
       "        [ 0.313728  ,  0.20475893,  0.59101164, -0.07041423, -0.172195  ,\n",
       "          0.3968525 ,  0.37256533, -0.17371103,  0.20850433, -0.5733746 ,\n",
       "         -0.18640967, -0.19104946]], dtype=float32)>,\n",
       " 'b3': <tf.Variable 'Variable:0' shape=(6, 1) dtype=float32, numpy=\n",
       " array([[ 0.07464749],\n",
       "        [-0.31648093],\n",
       "        [ 0.357774  ],\n",
       "        [-0.4854467 ],\n",
       "        [-0.5509955 ],\n",
       "        [-0.24964494]], dtype=float32)>}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(new_train, new_y_train, new_test, new_y_test, num_epochs=200)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output**\n",
    "\n",
    "```\n",
    "Cost after epoch 0: 0.742591\n",
    "Cost after epoch 10: 0.614557\n",
    "Cost after epoch 20: 0.598900\n",
    "Cost after epoch 30: 0.588907\n",
    "Cost after epoch 40: 0.579898\n",
    "...\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations**! You've made it to the end of this assignment, and to the end of this week's material. Amazing work building a neural network in TensorFlow 2.3! \n",
    "\n",
    "Here's a quick recap of all you just achieved:\n",
    "\n",
    "- Used `tf.Variable` to modify your variables\n",
    "- Applied TensorFlow decorators and observed how they sped up your code\n",
    "- Trained a Neural Network on a TensorFlow dataset\n",
    "\n",
    "You are now able to harness the power of TensorFlow's computational graph to create cool things, faster. Nice!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
