{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2928 - accuracy: 0.9157 - val_loss: 0.1349 - val_accuracy: 0.9607\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1416 - accuracy: 0.9579 - val_loss: 0.1024 - val_accuracy: 0.9701\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1055 - accuracy: 0.9679 - val_loss: 0.0834 - val_accuracy: 0.9771\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0856 - accuracy: 0.9733 - val_loss: 0.0750 - val_accuracy: 0.9774\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0733 - accuracy: 0.9771 - val_loss: 0.0786 - val_accuracy: 0.9773\n",
      "313/313 - 0s - loss: 0.0786 - accuracy: 0.9773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07862486690282822, 0.9772999882698059]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf  \n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# 加载 Mnist 数据集  \n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 数据归一化  \n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# 构建 LeNet 模型  \n",
    "model = tf.keras.models.Sequential([  \n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),  \n",
    "    tf.keras.layers.Dense(128, activation='relu'),  \n",
    "    tf.keras.layers.Dropout(0.2),  \n",
    "    tf.keras.layers.Dense(10)  \n",
    "])\n",
    "\n",
    "# 定义损失函数和优化器  \n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)  \n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# 训练模型  \n",
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])  \n",
    "model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
    "\n",
    "# 评估模型  \n",
    "model.evaluate(x_test,  y_test, verbose=2)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer conv2d_2 is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: [None, 784]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m x_train, x_test \u001b[39m=\u001b[39m x_train \u001b[39m/\u001b[39m \u001b[39m255.0\u001b[39m, x_test \u001b[39m/\u001b[39m \u001b[39m255.0\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[39m# 构建 LeNet 模型     \u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mSequential([    \n\u001b[0;32m     12\u001b[0m     tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mFlatten(input_shape\u001b[39m=\u001b[39;49m(\u001b[39m28\u001b[39;49m, \u001b[39m28\u001b[39;49m)),    \n\u001b[0;32m     13\u001b[0m     tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mConvolution2D(\u001b[39m128\u001b[39;49m, (\u001b[39m2\u001b[39;49m, \u001b[39m2\u001b[39;49m), activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m),    \n\u001b[0;32m     14\u001b[0m     tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mDropout(\u001b[39m0.2\u001b[39;49m),    \n\u001b[0;32m     15\u001b[0m     tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mConvolution2D(\u001b[39m10\u001b[39;49m, (\u001b[39m2\u001b[39;49m, \u001b[39m2\u001b[39;49m), activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m),    \n\u001b[0;32m     16\u001b[0m     tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mDropout(\u001b[39m0.2\u001b[39;49m)    \n\u001b[0;32m     17\u001b[0m ])\n\u001b[0;32m     19\u001b[0m \u001b[39m# 定义损失函数和优化器    \u001b[39;00m\n\u001b[0;32m     20\u001b[0m loss_fn \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mSparseCategoricalCrossentropy(from_logits\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)    \n",
      "File \u001b[1;32md:\\origin\\software\\program\\Anaconda\\envs\\MyJupterWorkerSpace\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py:457\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    456\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 457\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    458\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    459\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32md:\\origin\\software\\program\\Anaconda\\envs\\MyJupterWorkerSpace\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:142\u001b[0m, in \u001b[0;36mSequential.__init__\u001b[1;34m(self, layers, name)\u001b[0m\n\u001b[0;32m    140\u001b[0m   layers \u001b[39m=\u001b[39m [layers]\n\u001b[0;32m    141\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m layers:\n\u001b[1;32m--> 142\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd(layer)\n",
      "File \u001b[1;32md:\\origin\\software\\program\\Anaconda\\envs\\MyJupterWorkerSpace\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py:457\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    456\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 457\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    458\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    459\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32md:\\origin\\software\\program\\Anaconda\\envs\\MyJupterWorkerSpace\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:221\u001b[0m, in \u001b[0;36mSequential.add\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_explicit_input_shape \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutputs:\n\u001b[0;32m    219\u001b[0m   \u001b[39m# If the model is being built continuously on top of an input layer:\u001b[39;00m\n\u001b[0;32m    220\u001b[0m   \u001b[39m# refresh its output.\u001b[39;00m\n\u001b[1;32m--> 221\u001b[0m   output_tensor \u001b[39m=\u001b[39m layer(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutputs[\u001b[39m0\u001b[39;49m])\n\u001b[0;32m    222\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(nest\u001b[39m.\u001b[39mflatten(output_tensor)) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    223\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(SINGLE_LAYER_OUTPUT_ERROR_MSG)\n",
      "File \u001b[1;32md:\\origin\\software\\program\\Anaconda\\envs\\MyJupterWorkerSpace\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:925\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[39m# Functional Model construction mode is invoked when `Layer`s are called on\u001b[39;00m\n\u001b[0;32m    920\u001b[0m \u001b[39m# symbolic `KerasTensor`s, i.e.:\u001b[39;00m\n\u001b[0;32m    921\u001b[0m \u001b[39m# >> inputs = tf.keras.Input(10)\u001b[39;00m\n\u001b[0;32m    922\u001b[0m \u001b[39m# >> outputs = MyLayer()(inputs)  # Functional construction mode.\u001b[39;00m\n\u001b[0;32m    923\u001b[0m \u001b[39m# >> model = tf.keras.Model(inputs, outputs)\u001b[39;00m\n\u001b[0;32m    924\u001b[0m \u001b[39mif\u001b[39;00m _in_functional_construction_mode(\u001b[39mself\u001b[39m, inputs, args, kwargs, input_list):\n\u001b[1;32m--> 925\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m    926\u001b[0m                                             input_list)\n\u001b[0;32m    928\u001b[0m \u001b[39m# Maintains info about the `Layer.call` stack.\u001b[39;00m\n\u001b[0;32m    929\u001b[0m call_context \u001b[39m=\u001b[39m base_layer_utils\u001b[39m.\u001b[39mcall_context()\n",
      "File \u001b[1;32md:\\origin\\software\\program\\Anaconda\\envs\\MyJupterWorkerSpace\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1092\u001b[0m, in \u001b[0;36mLayer._functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1084\u001b[0m   base_layer_utils\u001b[39m.\u001b[39mcreate_keras_history(inputs)\n\u001b[0;32m   1086\u001b[0m \u001b[39mwith\u001b[39;00m call_context\u001b[39m.\u001b[39menter(\n\u001b[0;32m   1087\u001b[0m     layer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, inputs\u001b[39m=\u001b[39minputs, build_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39mtraining_value):\n\u001b[0;32m   1088\u001b[0m   \u001b[39m# Symbolic execution on symbolic tensors. We will attempt to build\u001b[39;00m\n\u001b[0;32m   1089\u001b[0m   \u001b[39m# the corresponding TF subgraph inside `backend.get_graph()`\u001b[39;00m\n\u001b[0;32m   1090\u001b[0m   \u001b[39m# TODO(reedwm): We should assert input compatibility after the inputs\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m   \u001b[39m# are casted, not before.\u001b[39;00m\n\u001b[1;32m-> 1092\u001b[0m   input_spec\u001b[39m.\u001b[39;49massert_input_compatibility(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_spec, inputs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[0;32m   1093\u001b[0m   graph \u001b[39m=\u001b[39m backend\u001b[39m.\u001b[39mget_graph()\n\u001b[0;32m   1094\u001b[0m   \u001b[39m# Use `self._name_scope()` to avoid auto-incrementing the name.\u001b[39;00m\n",
      "File \u001b[1;32md:\\origin\\software\\program\\Anaconda\\envs\\MyJupterWorkerSpace\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:191\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    189\u001b[0m   ndim \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape\u001b[39m.\u001b[39mndims\n\u001b[0;32m    190\u001b[0m   \u001b[39mif\u001b[39;00m ndim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m ndim \u001b[39m<\u001b[39m spec\u001b[39m.\u001b[39mmin_ndim:\n\u001b[1;32m--> 191\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mInput \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(input_index) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m of layer \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m\n\u001b[0;32m    192\u001b[0m                      layer_name \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m is incompatible with the layer: \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    193\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39m: expected min_ndim=\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(spec\u001b[39m.\u001b[39mmin_ndim) \u001b[39m+\u001b[39m\n\u001b[0;32m    194\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39m, found ndim=\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(ndim) \u001b[39m+\u001b[39m\n\u001b[0;32m    195\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39m. Full shape received: \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m\n\u001b[0;32m    196\u001b[0m                      \u001b[39mstr\u001b[39m(x\u001b[39m.\u001b[39mshape\u001b[39m.\u001b[39mas_list()))\n\u001b[0;32m    197\u001b[0m \u001b[39m# Check dtype.\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39mif\u001b[39;00m spec\u001b[39m.\u001b[39mdtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer conv2d_2 is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: [None, 784]"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf  \n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# 加载 Mnist 数据集  \n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 数据归一化  \n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# 构建 LeNet 模型     \n",
    "model = tf.keras.models.Sequential([    \n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),    \n",
    "    tf.keras.layers.Convolution2D(128, (2, 2), activation='relu'),    \n",
    "    tf.keras.layers.Dropout(0.2),    \n",
    "    tf.keras.layers.Convolution2D(10, (2, 2), activation='relu'),    \n",
    "    tf.keras.layers.Dropout(0.2)    \n",
    "])\n",
    "\n",
    "# 定义损失函数和优化器    \n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)    \n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# 训练模型    \n",
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])    \n",
    "model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
    "\n",
    "# 评估模型    \n",
    "model.evaluate(x_test,  y_test, verbose=2)    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyJupterWorkerSpace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
