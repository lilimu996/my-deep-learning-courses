{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 概述\n",
    "- **目标**：实现用神经网络来实现逻辑回归分类，并对深度学习有一个初步且直观的理解。\n",
    "- **具体实施方案**：构建神经网络来识别猫。\n",
    "- **你将学会**：\n",
    "    - 构建学习算法的常规框架，包括:\n",
    "        - 初始化参数\n",
    "        - 计算损失函数（cost function）及其梯度（gradient）\n",
    "        - 使用梯度下降法进行优化\n",
    "    - 将上述三种功能函数，以正确的顺序整合成一个训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - 包\n",
    "- [numpy](https://numpy.org/doc/1.20/) ：科学计算\n",
    "- [h5py](http://www.h5py.org)：存储、读取 H5 格式文件（保存了数据库）\n",
    "- [matplotlib](http://matplotlib.org)：画图\n",
    "- [PIL](https://pypi.org/project/Pillow/) ：读取图片。PIL全称是Python Imaging Library，python 2.7以后不再支持。pillow是PIL模块的一个派生分支，如今已经发展成为比PIL更具活力的图像处理库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from lib_lr_utils import load_dataset\n",
    "from lib_public_tests import *\n",
    "\n",
    "# 确保matplotlib的图表直接嵌入到Notebook之中\n",
    "%matplotlib inline\n",
    "# 确保在Notebook中使用最新的模块\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - 问题预览\n",
    "- **问题描述**: 给定数据库(\"*.h5\")中包含\n",
    "    - 具有 m_train 张图片的训练集，每一张被标记为 猫 (y=1) 或者 非猫 (y=0)\n",
    "    - 具有 m_test 张图片的测试集，每一张被标记为 猫 (y=1) 或者 非猫 (y=0)\n",
    "    - 每张图片的尺寸/形状为 (num_px, num_px, 3)，其中的 3 表示 RGB 三通道\n",
    "- **目标**：构建一个简单的图片识别算法来正确的区分 “猫” 与 “非猫”\n",
    "\n",
    "* 首先来看数据集，运行下面的代码来加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data (cat/non-cat)\n",
    "train_set_x, train_set_y, test_set_x, test_set_y, classes = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行下面的代码可视化 train_set_x 和 test_set_x 中的图片数据，修改 `index` 值可以在不同图片间进行切换。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example of a picture\n",
    "index = 50\n",
    "plt.imshow(train_set_x[index])\n",
    "print (\"y = \" + str(train_set_y[:, index]) + \", it's a '\" + \n",
    "       classes[np.squeeze(train_set_y[:, index])].decode(\"utf-8\") +  \"' picture.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 思考：为什么需要np.squeeze？\n",
    "print(train_set_y.shape)\n",
    "print(np.squeeze(train_set_y).shape) # np.squeeze() 将删除数组形状中的单维度条目，即把shape中为1的维度去掉\n",
    "\n",
    "print(np.squeeze(train_set_y[:, index]))\n",
    "print(train_set_y[:, index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 练习 1 - 理解数据维度\n",
    "- **目标**：深度学习中的许多问题出在 矩阵/向量 数据的维度不匹配，接下来请获取下列信息并了然于心:\n",
    "    - m_train (训练集数据量)\n",
    "    - m_test (测试集数据量)\n",
    "    - num_px (训练数据的宽/高)\n",
    "- 提示：`train_set_x` 是一个形状为 (m_train, num_px, num_px, 3) 的numpy数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "921fe679a632ec7ec9963069fa405725",
     "grade": false,
     "grade_id": "cell-c4e7e9c1f174eb83",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#(≈ 3 lines of code)\n",
    "# m_train = \n",
    "# m_test = \n",
    "# num_px = \n",
    "# YOUR CODE STARTS HERE\n",
    "\n",
    "# YOUR CODE ENDS HERE\n",
    "\n",
    "print (\"Number of training examples: m_train = \" + str(m_train))\n",
    "print (\"Number of testing examples: m_test = \" + str(m_test))\n",
    "print (\"Height/Width of each image: num_px = \" + str(num_px))\n",
    "print (\"Each image is of size: (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\n",
    "print (\"train_set_x shape: \" + str(train_set_x.shape))\n",
    "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
    "print (\"test_set_x shape: \" + str(test_set_x.shape))\n",
    "print (\"test_set_y shape: \" + str(test_set_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output for m_train, m_test and num_px**: \n",
    "<table style=\"width:15%\">\n",
    "  <tr>\n",
    "    <td> m_train </td>\n",
    "    <td> 209 </td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>m_test</td>\n",
    "    <td> 50 </td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>num_px</td>\n",
    "    <td> 64 </td> \n",
    "  </tr>\n",
    "  \n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 练习 2 - Reshape\n",
    "- **目标**：使得形状为 (num_px, num_px, 3) 的图片数据展开为（num_px $*$ num_px $*$ 3, 1）的列向量；对于训练集（测试集）来说，其中应该有 m_train（m_test）列这样的数据。\n",
    "\n",
    "- 提示：可以使用如下代码将一个形状为 (a,b,c,d) 的矩阵 X 改变为形状为 (b $*$ c $*$ d, $a$) 的矩阵 X_flatten:\n",
    "```\n",
    "        # X.T 表示 X 的转置\n",
    "        X_flatten = X.reshape(X.shape[0], -1).T\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5a2aa62bdd8c01450111b758ef159aec",
     "grade": false,
     "grade_id": "cell-0f43921062c34e50",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Reshape the training and test examples\n",
    "#(≈ 2 lines of code)\n",
    "# train_set_x_flatten = ...\n",
    "# test_set_x_flatten = ...\n",
    "# YOUR CODE STARTS HERE\n",
    "\n",
    "# YOUR CODE ENDS HERE\n",
    "\n",
    "# Check that the first 10 pixels of the second image are in the correct place\n",
    "assert np.alltrue(train_set_x_flatten[0:10, 1] == [196, 192, 190, 193, 186, 182, 188, 179, 174, 213]), \"Wrong solution. Use (X.shape[0], -1).T.\"\n",
    "assert np.alltrue(test_set_x_flatten[0:10, 1] == [115, 110, 111, 137, 129, 129, 155, 146, 145, 159]), \"Wrong solution. Use (X.shape[0], -1).T.\"\n",
    "\n",
    "print (\"train_set_x_flatten shape: \" + str(train_set_x_flatten.shape))\n",
    "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
    "print (\"test_set_x_flatten shape: \" + str(test_set_x_flatten.shape))\n",
    "print (\"test_set_y shape: \" + str(test_set_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "\n",
    "<table style=\"width:35%\">\n",
    "  <tr>\n",
    "    <td>train_set_x_flatten shape</td>\n",
    "    <td> (12288, 209)</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>train_set_y shape</td>\n",
    "    <td>(1, 209)</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>test_set_x_flatten shape</td>\n",
    "    <td>(12288, 50)</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>test_set_y shape</td>\n",
    "    <td>(1, 50)</td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在数字图像中，每个通道的像素值是 0 到 255 的整数，机器学习中的一项普遍预处理是对数据进行中心化和标准化（归一化），对于数字图像来说就是将每行除以其最大值（即255）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x = train_set_x_flatten / 255.\n",
    "test_set_x = test_set_x_flatten / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "    \n",
    "    \n",
    "**What you need to remember:**\n",
    "\n",
    "Common steps for pre-processing a new dataset are:\n",
    "- Figure out the dimensions and shapes of the problem (m_train, m_test, num_px, ...)\n",
    "- Reshape the datasets such that each example is now a vector of size (num_px \\* num_px \\* 3, 1)\n",
    "- \"Standardize\" the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - 模型框架\n",
    "\n",
    "下面将构建一个如下图所示的逻辑回归模型   \n",
    "<img src=\"images/LogReg_kiank.png\" width=1000>\n",
    "\n",
    "## 3.1 理论基础\n",
    "\n",
    "- 对于一个样本 $x^{(i)}$ 来说:\n",
    "    - 线性组合 $z^{(i)} = w^T x^{(i)} + b \\tag{1}$\n",
    "    - 激活函数 $\\hat{y}^{(i)} = a^{(i)} = sigmoid(z^{(i)})\\tag{2}$\n",
    "    - 损失（Loss）函数 $ \\mathcal{L}(a^{(i)}, y^{(i)}) =  - y^{(i)}  \\log(a^{(i)}) - (1-y^{(i)} )  \\log(1-a^{(i)})\\tag{3}$\n",
    "\n",
    "- 对于整个训练集来说：\n",
    "    - 代价（Cost）函数 $ J = \\frac{1}{m} \\sum_{i=1}^m \\mathcal{L}(a^{(i)}, y^{(i)})\\tag{4}$\n",
    "\n",
    "## 3.2 关键步骤\n",
    "- 初始化模型参数\n",
    "- 通过最小化代价函数进行模型参数学习\n",
    "- 使用学习到的参数在测试集上进行预测\n",
    "- 对实验结果进行分析并总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - 构建本实验算法的各个部分\n",
    "\n",
    "- 主要步骤：\n",
    "    1. 定义模型结构（例如输入特征的数量）\n",
    "    2. 初始化模型参数\n",
    "    3. 执行循环：\n",
    "        - 计算当前轮代价（前向传播）\n",
    "        - 计算当前轮梯度（反向传播）\n",
    "        - 更新参数（梯度下降）\n",
    "- 可以分别实现 1-3 步骤，然后将他们整合到一个名为 `model()` 的函数中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 - 初始化参数\n",
    "\n",
    "### 练习 3 - initialize_with_zeros\n",
    "- **目标**：将变量 w 初始化为一个全零的向量，b初始化为 0 \n",
    "- 提示：使用 np.zeros() 函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c4a37e375a85ddab7274a33abf46bb7c",
     "grade": false,
     "grade_id": "cell-befa9335e479864e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    This function creates a vector of zeros of shape (dim, 1) for w and initializes b to 0.    \n",
    "    Argument:\n",
    "    dim -- size of the w vector we want (or number of parameters in this case)    \n",
    "    Returns:\n",
    "    w -- initialized vector of shape (dim, 1)\n",
    "    b -- initialized scalar (corresponds to the bias) of type float\n",
    "\"\"\"   \n",
    "def initialize_with_zeros(dim):     \n",
    "    # (≈ 2 lines of code)\n",
    "    # w = ...\n",
    "    # b = ...\n",
    "    # YOUR CODE STARTS HERE\n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a1f856df8b35b664982b6e4ca82681cf",
     "grade": true,
     "grade_id": "cell-a3b6699f145f3a3f",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dim = 2\n",
    "w, b = initialize_with_zeros(dim)\n",
    "\n",
    "assert type(b) == float\n",
    "print (\"w = \" + str(w))\n",
    "print (\"b = \" + str(b))\n",
    "\n",
    "initialize_with_zeros_test(initialize_with_zeros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 - 前向传播和反向传播\n",
    "\n",
    "### 练习 4 - sigmoid\n",
    "- **目标**：实现一个sigmoid函数（参考实验0中的代码`sigmoid()`）。在前向传播中需要调用该函数作为激活函数，即 $sigmoid(z) = \\frac{1}{1 + e^{-z}}$，其中 $z = w^T x + b$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Compute the sigmoid of z\n",
    "    Arguments:\n",
    "    z -- A scalar or numpy array of any size.\n",
    "    Return:\n",
    "    s -- sigmoid(z)\n",
    "\"\"\"\n",
    "def sigmoid(z):\n",
    "    #(≈ 1 line of code)\n",
    "    # s = ...\n",
    "    # YOUR CODE STARTS HERE\n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0483e6820669111a9c5914d8b24bc315",
     "grade": true,
     "grade_id": "cell-30ea3151cab9c491",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print (\"sigmoid([0, 2]) = \" + str(sigmoid(np.array([0,2]))))\n",
    "\n",
    "sigmoid_test(sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习 5 - propagate\n",
    "- **目标**：实现函数 `propagate()` 用来计算代价函数和它的梯度\n",
    "- **提示**：\n",
    "1. 前向传播\n",
    "    - 输入 X 和 Y\n",
    "    - 计算 $A = \\sigma(w^T X + b) = (a^{(1)}, a^{(2)}, \\cdots, a^{(m-1)}, a^{(m)})$\n",
    "    - 计算代价函数（交叉熵）： $J = -\\frac{1}{m}\\sum_{i=1}^{m}(y^{(i)}\\log(a^{(i)})+(1-y^{(i)})\\log(1-a^{(i)}))$\n",
    "2. 梯度计算\n",
    "$$ \\frac{\\partial J}{\\partial w} = \\frac{1}{m}X(A-Y)^T\\tag{5}$$\n",
    "$$ \\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^m (a^{(i)}-y^{(i)})\\tag{6}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8c7fa5fd813679d86ba0032de1f813eb",
     "grade": false,
     "grade_id": "cell-11af17e28077b3d3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function:\n",
    "    Implement the cost function and its gradient for the propagation explained above\n",
    "Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of size (num_px * num_px * 3, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat) of size (1, number of examples)\n",
    "Return:\n",
    "    cost -- negative log-likelihood cost for logistic regression\n",
    "    dw -- gradient of the loss with respect to w, thus same shape as w\n",
    "    db -- gradient of the loss with respect to b, thus same shape as b    \n",
    "Tips:\n",
    "    Write your code step by step for the propagation. np.log(), np.dot()\n",
    "\"\"\"\n",
    "def propagate(w, b, X, Y):    \n",
    "    m = X.shape[1]\n",
    "    # FORWARD PROPAGATION (FROM X TO COST)\n",
    "    #(≈ 2 lines of code)\n",
    "    # A = ...\n",
    "    # cost = ...                                \n",
    "    # YOUR CODE STARTS HERE\n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "\n",
    "    # BACKWARD PROPAGATION (TO FIND GRAD)\n",
    "    #(≈ 2 lines of code)\n",
    "    # dw = ...\n",
    "    # db = ...\n",
    "    # YOUR CODE STARTS HERE\n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    #cost = np.squeeze(np.array(cost))    # np.squeeze() 将删除数组形状中的单维度条目，即把shape中为1的维度去掉\n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}    \n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "48874865ce7cec6f03c3fae76f8bbfbe",
     "grade": true,
     "grade_id": "cell-d1594d75b61dd554",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "w =  np.array([[1.], [2.]])\n",
    "b = 2.\n",
    "X =np.array([[1., 2., -1.], [3., 4., -3.2]])\n",
    "Y = np.array([[1, 0, 1]])\n",
    "grads, cost = propagate(w, b, X, Y)\n",
    "\n",
    "assert type(grads[\"dw\"]) == np.ndarray\n",
    "assert grads[\"dw\"].shape == (2, 1)\n",
    "assert type(grads[\"db\"]) == np.float64\n",
    "\n",
    "print (\"dw = \" + str(grads[\"dw\"]))\n",
    "print (\"db = \" + str(grads[\"db\"]))\n",
    "print (\"cost = \" + str(cost))\n",
    "\n",
    "propagate_test(propagate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output**\n",
    "\n",
    "```\n",
    "dw = [[0.99845601]\n",
    " [2.39507239]]\n",
    "db = 0.001455578136784208\n",
    "cost = 5.801545319394553\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 - 优化\n",
    "### 练习 6 - optimize\n",
    "- **目标**：通过最小化代价函数 $J$  来学习 $w$ 和 $b$。对于一个参数 $\\theta$，更新规则是 $ \\theta = \\theta - \\alpha \\text{ } d\\theta$，其中 $\\alpha$ 是学习率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49d9b4c1a780bf141c8eb48e06cbb494",
     "grade": false,
     "grade_id": "cell-616d6883e807448d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function:\n",
    "    This function optimizes w and b by running a gradient descent algorithm    \n",
    "Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of shape (num_px * num_px * 3, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat), of shape (1, number of examples)\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    print_cost -- True to print the loss every 100 steps\n",
    "Returns:\n",
    "    params -- dictionary containing the weights w and bias b\n",
    "    grads -- dictionary containing the gradients of the weights and bias with respect to the cost function\n",
    "    costs -- list of all the costs computed during the optimization, this will be used to plot the learning curve.\n",
    "Tips:\n",
    "    You basically need to write down two steps and iterate through them:\n",
    "        1) Calculate the cost and the gradient for the current parameters. Use propagate().\n",
    "        2) Update the parameters using gradient descent rule for w and b.\n",
    "\"\"\"    \n",
    "def optimize(w, b, X, Y, num_iterations=100, learning_rate=0.009, print_cost=False):    \n",
    "    w = copy.deepcopy(w)\n",
    "    b = copy.deepcopy(b)    \n",
    "    costs = []    \n",
    "    for i in range(num_iterations):\n",
    "        # (≈ 1 lines of code)\n",
    "        # Cost and gradient calculation \n",
    "        # grads, cost = ...\n",
    "        # YOUR CODE STARTS HERE\n",
    "        \n",
    "        # YOUR CODE ENDS HERE\n",
    "        \n",
    "        # Retrieve derivatives from grads\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        # update rule (≈ 2 lines of code)\n",
    "        # w = ...\n",
    "        # b = ...\n",
    "        # YOUR CODE STARTS HERE\n",
    "        \n",
    "        # YOUR CODE ENDS HERE\n",
    "        \n",
    "        # Record the costs\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost) \n",
    "            if print_cost: # Print the cost every 100 training iterations\n",
    "                print (\"Cost after iteration {}: {}\".format(i, cost))\n",
    "    \n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b65a5c90f86a990614156e41f64b4678",
     "grade": true,
     "grade_id": "cell-8e3d43fbb82a8901",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "params, grads, costs = optimize(w, b, X, Y, num_iterations=100, learning_rate=0.009, print_cost=False)\n",
    "\n",
    "print (\"w = \" + str(params[\"w\"]))\n",
    "print (\"b = \" + str(params[\"b\"]))\n",
    "print (\"dw = \" + str(grads[\"dw\"]))\n",
    "print (\"db = \" + str(grads[\"db\"]))\n",
    "print(\"Costs = \" + str(costs))\n",
    "\n",
    "optimize_test(optimize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习 7 - predict\n",
    "- **目标**：实现一个函数 `predict()`，包含2步\n",
    "    1. 计算 $\\hat{Y} = A = \\sigma(w^T X + b)$\n",
    "    2. 将结果转换为 0 当 activation <= 0.5；或者 1 当 activation > 0.5)，将其存储在向量 `Y_prediction` 中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e56419b97ebf382a8f93ac2873988887",
     "grade": false,
     "grade_id": "cell-d6f924f49c51dc2f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function:\n",
    "    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)    \n",
    "Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of size (num_px * num_px * 3, number of examples)\n",
    "Returns:\n",
    "    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n",
    "'''\n",
    "def predict(w, b, X):        \n",
    "    m = X.shape[1]\n",
    "    Y_prediction = np.zeros((1, m))\n",
    "    w = w.reshape(X.shape[0], 1)    \n",
    "    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n",
    "    #(≈ 1 line of code)\n",
    "    # A = ...\n",
    "    # YOUR CODE STARTS HERE\n",
    "    \n",
    "    # YOUR CODE ENDS HERE    \n",
    "    for i in range(A.shape[1]):\n",
    "        # Convert probabilities A[0,i] to actual predictions p[0,i]\n",
    "        #(≈ 4 lines of code)\n",
    "        # if A[0, i] > ____ :\n",
    "        #     Y_prediction[0,i] = \n",
    "        # else:\n",
    "        #     Y_prediction[0,i] = \n",
    "        # YOUR CODE STARTS HERE\n",
    "        \n",
    "        # YOUR CODE ENDS HERE\n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e3ea12608f15798d542a07c1bc9f561b",
     "grade": true,
     "grade_id": "cell-90b1fb967269548c",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "w = np.array([[0.1124579], [0.23106775]])\n",
    "b = -0.3\n",
    "X = np.array([[1., -1.1, -3.2],[1.2, 2., 0.1]])\n",
    "print (\"predictions = \" + str(predict(w, b, X)))\n",
    "\n",
    "predict_test(predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "    \n",
    "**What to remember:**\n",
    "    \n",
    "You've implemented several functions that:\n",
    "- Initialize (w,b)\n",
    "- Optimize the loss iteratively to learn parameters (w,b):\n",
    "    - Computing the cost and its gradient \n",
    "    - Updating the parameters using gradient descent\n",
    "- Use the learned (w,b) to predict the labels for a given set of examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - 整合所有函数\n",
    "\n",
    "## 练习 8 - model\n",
    "- **目标**：实现一个函数 `model` ，按正确的顺序整合调用上述函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5b84120627479b28a106a86b61efd80e",
     "grade": false,
     "grade_id": "cell-6dcba5967c4cbf8c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function:\n",
    "    Builds the logistic regression model by calling the function you've implemented previously\n",
    "Arguments:\n",
    "    X_train -- training set represented by a numpy array of shape (num_px * num_px * 3, m_train)\n",
    "    Y_train -- training labels represented by a numpy array (vector) of shape (1, m_train)\n",
    "    X_test -- test set represented by a numpy array of shape (num_px * num_px * 3, m_test)\n",
    "    Y_test -- test labels represented by a numpy array (vector) of shape (1, m_test)\n",
    "    num_iterations -- hyperparameter representing the number of iterations to optimize the parameters\n",
    "    learning_rate -- hyperparameter representing the learning rate used in the update rule of optimize()\n",
    "    print_cost -- Set to True to print the cost every 100 iterations\n",
    "Returns:\n",
    "    d -- dictionary containing information about the model.\n",
    "\"\"\"\n",
    "def model(X_train, Y_train, X_test, Y_test, num_iterations=2000, learning_rate=0.5, print_cost=False):\n",
    "    \n",
    "    # YOUR CODE STARTS HERE \n",
    "    # 初始化参数为全0值 (≈ 1 line of code)   \n",
    "    \n",
    "     \n",
    "    # 梯度下降 (≈ 1 line of code)\n",
    "    \n",
    "    \n",
    "    # 获取训练好的模型参数\n",
    "    w = parameters[\"w\"]\n",
    "    b = parameters[\"b\"]\n",
    "    \n",
    "    # 对测试集和训练集进行预测 (≈ 2 lines of code)\n",
    "      \n",
    "    # YOUR CODE ENDS HERE\n",
    "\n",
    "    # 计算并打印准确率\n",
    "    if print_cost:\n",
    "        print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
    "        print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100)) \n",
    "    \n",
    "    # 最终的返回信息包括：代价，训练集和测试集上的输出，参数和偏置，学习率和迭代次数\n",
    "    d = {\"costs\": costs,\n",
    "         \"Y_prediction_test\": Y_prediction_test, \n",
    "         \"Y_prediction_train\" : Y_prediction_train, \n",
    "         \"w\" : w, \n",
    "         \"b\" : b,\n",
    "         \"learning_rate\" : learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ef861169461a4c80af845379770efe90",
     "grade": true,
     "grade_id": "cell-4170e070f3cde17e",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "model_test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you pass all the tests, run the following cell to train your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_model = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations=2000, learning_rate=0.005, print_cost=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **分析**: \n",
    "    - 训练集准确率接近100%。表明该模型在训练集上面是有效的。 \n",
    "    - 测试集准确性为70%。作为一个简单的模型来说，准确率还算不错，后续将构建更好的分类器。\n",
    "- **结论**：\n",
    "    - 过拟合\n",
    "    - 可以使用正则化方法来降低过拟合\n",
    "- 使用下面的代码查看预测结果(通过改变 `index` 变量的值可以在不同测试图片间进行切换)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a picture that was wrongly classified.\n",
    "index = 5\n",
    "plt.imshow(test_set_x[:, index].reshape((num_px, num_px, 3)))\n",
    "print (\"y = \" + str(test_set_y[0,index]) + \", you predicted that it is a \\\"\" + classes[int(logistic_regression_model['Y_prediction_test'][0,index])].decode(\"utf-8\") +  \"\\\" picture.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可视化代价变化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curve (with costs)\n",
    "# costs = np.squeeze(logistic_regression_model['costs'])\n",
    "costs = logistic_regression_model['costs']\n",
    "plt.plot(costs)\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (per hundreds)')\n",
    "plt.title(\"Learning rate =\" + str(logistic_regression_model[\"learning_rate\"]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 - 分析 (optional/ungraded exercise)\n",
    "\n",
    "## 6.1 学习率选取\n",
    "\n",
    "- 在进行梯度下降时需要我们合理选择学习率$\\alpha$，其决定了参数更新的速度\n",
    "- 如果过大，可能会\"overshoot\"最优值；反之，则需要更多次的迭代才能收敛至最优值。因此微调学习率非常关键\n",
    "\n",
    "下面将对比三组不同学习率下的代价曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "models = {}\n",
    "\n",
    "for lr in learning_rates:\n",
    "    print (\"Training a model with learning rate: \" + str(lr))\n",
    "    models[str(lr)] = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations=1500, learning_rate=lr, print_cost=False)\n",
    "    print ('\\n' + \"-------------------------------------------------------\" + '\\n')\n",
    "\n",
    "for lr in learning_rates:\n",
    "    plt.plot(np.squeeze(models[str(lr)][\"costs\"]), label=str(models[str(lr)][\"learning_rate\"]))\n",
    "\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (hundreds)')\n",
    "\n",
    "legend = plt.legend(loc='upper center', shadow=True)\n",
    "frame = legend.get_frame()\n",
    "frame.set_facecolor('0.90')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **解读**: \n",
    "    - 当学习率较大时(0.01)，代价曲线会上下震荡 \n",
    "    - 较低的代价并不一定就是一个好的模型，也可能是过拟合\n",
    "- **建议**：\n",
    "    - 选择能最小化代价函数的学习率\n",
    "    - 如果出现过拟合问题，使用正则化方法减少过拟合\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 - 测试自己的图片 (optional/ungraded exercise) ##\n",
    "\n",
    "将自己的图片存放到本Notebook的同一级目录下的images子目录中，修改下面代码中的`my_image`变量为对应的文件名并运行代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this to the name of your image file\n",
    "my_image = \"my_image2.jpg\"   \n",
    "\n",
    "# We preprocess the image to fit your algorithm.\n",
    "fname = \"images/\" + my_image\n",
    "image = np.array(Image.open(fname).resize((num_px, num_px))) # 使用PIL库的Image类\n",
    "plt.imshow(image)\n",
    "image = image / 255.\n",
    "# image = image.reshape((1, num_px * num_px * 3)).T\n",
    "image = image.reshape((num_px * num_px * 3, 1 ))\n",
    "my_predicted_image = predict(logistic_regression_model[\"w\"], logistic_regression_model[\"b\"], image)\n",
    "\n",
    "print(\"y = \" + str(np.squeeze(my_predicted_image)) + \", your algorithm predicts a \\\"\" + \n",
    "      classes[int(np.squeeze(my_predicted_image)),].decode(\"utf-8\") +  \"\\\" picture.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "    \n",
    "**What to remember from this assignment:**\n",
    "1. Preprocessing the dataset is important.\n",
    "2. You implemented each function separately: initialize(), propagate(), optimize(). Then you built a model().\n",
    "3. Tuning the learning rate (which is an example of a \"hyperparameter\") can make a big difference to the algorithm. You will see more examples of this later in this course!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, if you'd like, we invite you to try different things on this Notebook. Make sure you submit before trying anything. Once you submit, things you can play with include:\n",
    "    - Play with the learning rate and the number of iterations\n",
    "    - Try different initialization methods and compare the results\n",
    "    - Test other preprocessings (center the data, or divide each row by its standard deviation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bibliography:\n",
    "- http://www.wildml.com/2015/09/implementing-a-neural-network-from-scratch/\n",
    "- https://stats.stackexchange.com/questions/211436/why-do-we-normalize-images-by-subtracting-the-datasets-image-mean-and-not-the-c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
