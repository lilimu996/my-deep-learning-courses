{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实验9 残差网络\n",
    "\n",
    "本实验中你将使用残差网络来构建一个非常深的CNN.\n",
    "理论上来说, 非常深的网络能够表达非常复杂的函数. 但实际中, 非常深的网络很难训练(由于梯度爆炸/消失等问题).\n",
    "残差网络(Residual Networks), 由 [He 等人提出](https://arxiv.org/pdf/1512.03385.pdf), 使得训练较深的网络结构成为可能.\n",
    "\n",
    "**实验目标:**\n",
    "\n",
    "- 使用Keras来实验一个基础的残差块\n",
    "- 将残差块组合成模型并训练一个性能优秀的CNN用于图像分类\n",
    "- 在你自己的网络结构中实现跳跃连接(skip connection)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## 1 - 包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from lib_resnets_utils import *\n",
    "from tensorflow.keras.initializers import random_uniform, glorot_uniform, constant, identity\n",
    "from tensorflow.python.framework.ops import EagerTensor\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "from lib_test_utils import summary, comparator\n",
    "import lib_public_tests\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2 - 非常深的神经网络存在的问题\n",
    "\n",
    "在前面的实验中, 你构建了自己的第一个CNN: 先通过Numpy来实现, 后采用TF和Keras的API来实现.\n",
    "\n",
    "几年来, CNN开始变得越来越深. 从一开始仅有数层的AlexNet发展到拥有数百层的网络.\n",
    "\n",
    "* 一方面, 越深的网络表达能力通常越强.\n",
    "\n",
    "* 另一方面, 当层数变多, 往往会出现梯度快速趋向于0的情况, 且越低的层, 其趋近于0的速度越快. 这使得梯度下降优化变得非常慢.\n",
    "\n",
    "下图展示了随着迭代次数的增加, 不同层的梯度强度的大小.\n",
    "\n",
    "<img src=\"images/vanishing_grad_kiank.png\" style=\"width:450px;height:220px;\">\n",
    "\n",
    "别着急! 你将通过引入残差网络来解决该问题"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## 3 - 构建一个残差网络 ResNets\n",
    "\n",
    "在ResNets中, 一个 \"shortcut\" 或者 \"skip connection\" 允许模型跳跃几层:\n",
    "\n",
    "<img src=\"images/skip_connection_kiank.png\" width=1000>\n",
    "\n",
    "上图左展示了网络中的\"主路径\". 上图右在主路径上添加了一个跳跃路径.\n",
    "将残差块连起来, 你可以得到一个非常深的网络结构.\n",
    "\n",
    "在残差块中, 网络可以非常方便地学习得到一个恒等函数.\n",
    "这意味着, 在一个深层网络中, 有些残差块可以以恒等变换的方式存在, 防止网络性能的下级(因为加上残差块以后, 其输入输出没有发生变化).\n",
    "\n",
    "根据残差块的输入输出尺寸是否一致, 可将其分为identity block(即尺寸相同)和convolutional block(即尺寸不同)两类."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3-1'></a>\n",
    "### 3.1 - The identity block\n",
    "\n",
    "标准的残差块其输入(例如 $a^{[l]}$)和输出(例如 $a^{[l+2]}$)的尺寸是相同的, 称之为identity block.\n",
    "下图展示了相关流程:\n",
    "\n",
    "<img src=\"images/idblock2_kiank.png\" width=1000>\n",
    "\n",
    "图中上方的路径是\"shortcut path.\" 下方则是\"main path.\" 在流程图中, 注意每一层中的 CONV2D 和 ReLU 步骤. 为了加速训练, 添加了一个 BatchNorm 步骤.\n",
    "别着急, 在Keras中仅需1行代码即可实现BatchNorm!\n",
    "\n",
    "在下面的练习中, 你将实现一个比上图模型稍有不同的版本. 如下图所示, 你将跳跃3个隐藏层, 而非上图中的2个隐藏层:\n",
    "\n",
    "<img src=\"images/idblock3_kiank.png\" width=1000>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "具体实现分以下几个步骤:\n",
    "\n",
    "1. 主路径第一部分:\n",
    "    - 第一个 CONV2D 具有 $F_1$ 个 (1,1) 的滤波器, 步长为 (1,1). Padding 模式为 \"valid\" (注: 1×1的卷积不需要进行Padding). 使用0作为种子点进行初始化: `kernel_initializer = initializer(seed=0)`.\n",
    "    - 第一个 BatchNorm 对 'channels' 轴进行归一化.\n",
    "    - 然后应用 ReLU 激活函数. 没有超参数.\n",
    "2. 主路径第二部分:\n",
    "    - 第二个 CONV2D 具有 $F_2$ 个$(f,f)$ 的滤波器, 步长为 (1,1). Padding 模式为 \"same\". 使用0作为种子点进行初始化: `kernel_initializer = initializer(seed=0)`.\n",
    "    - 第二个 BatchNorm 对 'channels' 轴进行归一化.\n",
    "    - 然后应用 ReLU 激活函数. 没有超参数.\n",
    "3. 主路径第三部分:\n",
    "    - 第三个 CONV2D 具有 $F_3$ 个 (1,1) 的滤波器, 步长为 (1,1). Padding 模式为 \"valid\". 使用0作为种子点进行初始化: `kernel_initializer = initializer(seed=0)`.\n",
    "    - 第三个 BatchNorm 对 'channels' 轴进行归一化.\n",
    "    - 注意这部分 **没有** 使用 ReLU 激活.\n",
    "4. 跳跃连接:\n",
    "    - 对`X_shortcut` 与第三层的输出 `X` 进行相加操作.\n",
    "    - **提示**: 上述相加操作的语法伪代码是 `Add()([var1,var2])`\n",
    "    - 然后应用 ReLU 激活函数. 没有超参数.\n",
    "\n",
    "<a name='ex-1'></a>\n",
    "#### 练习 1 - identity_block\n",
    "\n",
    "实现identity block类型的残差网络. 上述主路径第一部分代码已经给出! 请仔细阅读并理解, 然后实现其余部分.\n",
    "注意, 上次实验中介绍了TF的Functional API, 此处需要借助这类API来创建跳跃连接."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0017b68317ffa974",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function:\n",
    "    Implementation of the identity block as defined in Figure 4\n",
    "Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    training -- True: Behave in training mode\n",
    "                False: Behave in inference mode\n",
    "    initializer -- to set up the initial weights of a layer. Equals to random uniform initializer\n",
    "Returns:\n",
    "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
    "\"\"\"\n",
    "def identity_block(X, f, filters, training=True, initializer=random_uniform):\n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value. You'll need this later to add back to the main path. \n",
    "    X_shortcut = X\n",
    "    \n",
    "    # First component of main path\n",
    "    X = Conv2D(filters = F1, kernel_size = 1, strides = (1,1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training) # Default axis\n",
    "    X = Activation('relu')(X)\n",
    "    ### START CODE HERE\n",
    "    ## Second component of main path (≈3 lines)\n",
    "    # X = None\n",
    "    # X = None\n",
    "    # X = None\n",
    "    X = Conv2D(filters = F2, kernel_size = f,strides = (1, 1),padding='same',kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training=training)\n",
    "    X = Activation('relu')(X)\n",
    "    ## Third component of main path (≈2 lines)\n",
    "    # X = None\n",
    "    # X = None\n",
    "    X = Conv2D(filters = F3, kernel_size = 1, strides = (1, 1), padding='valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training=training)\n",
    "    ## Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    # X = None\n",
    "    # X = None\n",
    "    X = Add()([X_shortcut,X])\n",
    "    X = Activation('relu')(X)\n",
    "    ### END CODE HERE\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e73a8466b807e261",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mWith training=False\u001b[0m\n",
      "\n",
      "[[[  0.        0.        0.        0.     ]\n",
      "  [  0.        0.        0.        0.     ]]\n",
      "\n",
      " [[192.7123  192.7123  192.7123   96.85615]\n",
      "  [ 96.85615  96.85615  96.85615  48.92808]]\n",
      "\n",
      " [[578.1369  578.1369  578.1369  290.56845]\n",
      "  [290.56845 290.56845 290.56845 146.78423]]]\n",
      "96.85615\n",
      "\n",
      "\u001b[1mWith training=True\u001b[0m\n",
      "\n",
      "[[[0.      0.      0.      0.     ]\n",
      "  [0.      0.      0.      0.     ]]\n",
      "\n",
      " [[0.40739 0.40739 0.40739 0.40739]\n",
      "  [0.40739 0.40739 0.40739 0.40739]]\n",
      "\n",
      " [[4.99991 4.99991 4.99991 3.25948]\n",
      "  [3.25948 3.25948 3.25948 2.40739]]]\n",
      "\u001b[32mAll tests passed!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "X1 = np.ones((1, 4, 4, 3)) * -1\n",
    "X2 = np.ones((1, 4, 4, 3)) * 1\n",
    "X3 = np.ones((1, 4, 4, 3)) * 3\n",
    "\n",
    "X = np.concatenate((X1, X2, X3), axis = 0).astype(np.float32)\n",
    "\n",
    "A3 = identity_block(X, f=2, filters=[4, 4, 3],\n",
    "                   initializer=lambda seed=0:constant(value=1),\n",
    "                   training=False)\n",
    "print('\\033[1mWith training=False\\033[0m\\n')\n",
    "A3np = A3.numpy()\n",
    "print(np.around(A3.numpy()[:,(0,-1),:,:].mean(axis = 3), 5))\n",
    "resume = A3np[:,(0,-1),:,:].mean(axis = 3)\n",
    "print(resume[1, 1, 0])\n",
    "\n",
    "print('\\n\\033[1mWith training=True\\033[0m\\n')\n",
    "np.random.seed(1)\n",
    "A4 = identity_block(X, f=2, filters=[3, 3, 3],\n",
    "                   initializer=lambda seed=0:constant(value=1),\n",
    "                   training=True)\n",
    "print(np.around(A4.numpy()[:,(0,-1),:,:].mean(axis = 3), 5))\n",
    "\n",
    "lib_public_tests.identity_block_test(identity_block)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3-2'></a>\n",
    "### 3.2 - The convolutional block\n",
    "\n",
    "第二类残差块称为 \"convolutional block\". 由于主路径的输入输出尺寸不一致, 因此需要如下图所示, 在跳跃连接处进行一次CONV2D, 以确保两者尺寸一致, 方可以进行相加操作:\n",
    "\n",
    "<img src=\"images/convblock_kiank.png\" width=1000>\n",
    "\n",
    "将激活数据尺寸降低一半, 你可以使用步长为2的 1x1 卷积.\n",
    "\n",
    "实现 convolutional block 的具体步骤如下:\n",
    "\n",
    "1. 主路径第一部分:\n",
    "    - 第一个 CONV2D 具有 $F_1$ 个 (1,1) 的滤波器, 步长为 (s,s). Padding 模式为 \"valid\". 使用0作为种子点进行初始化: `kernel_initializer = initializer(seed=0)`.\n",
    "    - 第一个 BatchNorm 对 'channels' 轴进行归一化.\n",
    "    - 然后应用 ReLU 激活函数. 没有超参数.\n",
    "2. 主路径第二部分:\n",
    "    - 第二个 CONV2D 具有 $F_2$ 个$(f,f)$ 的滤波器, 步长为 (1,1). Padding 模式为 \"same\". 使用0作为种子点进行初始化: `kernel_initializer = initializer(seed=0)`.\n",
    "    - 第二个 BatchNorm 对 'channels' 轴进行归一化.\n",
    "    - 然后应用 ReLU 激活函数. 没有超参数.\n",
    "3. 主路径第三部分:\n",
    "    - 第三个 CONV2D 具有 $F_3$ 个 (1,1) 的滤波器, 步长为 (1,1). Padding 模式为 \"valid\". 使用0作为种子点进行初始化: `kernel_initializer = initializer(seed=0)`.\n",
    "    - 第三个 BatchNorm 对 'channels' 轴进行归一化.\n",
    "    - 注意这部分 **没有** 使用 ReLU 激活.\n",
    "4. 跳跃路径第一部分:\n",
    "    - 使用一个 CONV2D 具有 $F_3$ 个 (1,1) 的滤波器, 步长为 (s,s). Padding 模式为 \"valid\". 使用0作为种子点进行初始化: `kernel_initializer = initializer(seed=0)`.\n",
    "    - 使用 BatchNorm 对 'channels' 轴进行归一化.\n",
    "5. 跳跃连接:\n",
    "    - 将 shortcut 和 main path 值相加.\n",
    "    - 应用 ReLU 激活函数. 没有超参数.\n",
    "\n",
    "<a name='ex-2'></a>    \n",
    "#### 练习 2 - convolutional_block\n",
    "实现 convolutional block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-df47af4847e5335f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function:\n",
    "    Implementation of the convolutional block as defined in Figure 4\n",
    "Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    s -- Integer, specifying the stride to be used\n",
    "    training -- True: Behave in training mode\n",
    "                False: Behave in inference mode\n",
    "    initializer -- to set up the initial weights of a layer. Equals to Glorot uniform initializer,\n",
    "                   also called Xavier uniform initializer.\n",
    "Returns:\n",
    "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
    "\"\"\"\n",
    "def convolutional_block(X, f, filters, s = 2, training=True, initializer=glorot_uniform):\n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "    ##### MAIN PATH #####\n",
    "    # First component of main path glorot_uniform(seed=0)\n",
    "    X = Conv2D(filters = F1, kernel_size = 1, strides = (s, s), padding='valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training=training)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    ### START CODE HERE\n",
    "    ## Second component of main path (≈3 lines)\n",
    "    # X = None\n",
    "    # X = None\n",
    "    # X = None\n",
    "    X = Conv2D(filters = F2, kernel_size = f,strides = (1, 1),padding='same',kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training=training)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    ## Third component of main path (≈2 lines)\n",
    "    # X = None\n",
    "    # X = None\n",
    "    X = Conv2D(filters = F3, kernel_size = 1, strides = (1, 1), padding='valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training=training)\n",
    "    ##### SHORTCUT PATH ##### (≈2 lines)\n",
    "    # X_shortcut = None\n",
    "    # X_shortcut = None\n",
    "    X_shortcut = Conv2D(filters = F3, kernel_size = 1, strides = (s, s), padding='valid', kernel_initializer = initializer(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3)(X_shortcut, training=training)\n",
    "    # Final step: Add shortcut value to main path (Use this order [X, X_shortcut]), and pass it through a RELU activation\n",
    "    # X = None\n",
    "    # X = None\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    ### END CODE HERE\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-95c291eb244218fe",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0.         0.66683805 0.         0.         0.888539   0.5274254 ]\n",
      "  [0.         0.65053654 0.         0.         0.8959285  0.49965227]]\n",
      "\n",
      " [[0.         0.63120776 0.         0.         0.86362475 0.47643146]\n",
      "  [0.         0.568832   0.         0.         0.8553412  0.417093  ]]], shape=(2, 2, 6), dtype=float32)\n",
      "\u001b[92mAll tests passed!\n"
     ]
    }
   ],
   "source": [
    "from lib_outputs import convolutional_block_output1, convolutional_block_output2\n",
    "np.random.seed(1)\n",
    "#X = np.random.randn(3, 4, 4, 6).astype(np.float32)\n",
    "X1 = np.ones((1, 4, 4, 3)) * -1\n",
    "X2 = np.ones((1, 4, 4, 3)) * 1\n",
    "X3 = np.ones((1, 4, 4, 3)) * 3\n",
    "\n",
    "X = np.concatenate((X1, X2, X3), axis = 0).astype(np.float32)\n",
    "\n",
    "A = convolutional_block(X, f = 2, filters = [2, 4, 6], training=False)\n",
    "\n",
    "assert type(A) == EagerTensor, \"Use only tensorflow and keras functions\"\n",
    "assert tuple(tf.shape(A).numpy()) == (3, 2, 2, 6), \"Wrong shape.\"\n",
    "assert np.allclose(A.numpy(), convolutional_block_output1), \"Wrong values when training=False.\"\n",
    "print(A[0])\n",
    "\n",
    "B = convolutional_block(X, f = 2, filters = [2, 4, 6], training=True)\n",
    "assert np.allclose(B.numpy(), convolutional_block_output2), \"Wrong values when training=True.\"\n",
    "\n",
    "print('\\033[92mAll tests passed!')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='4'></a>  \n",
    "## 4 - 构建你的第一个残差网络模型 (含 50 层)\n",
    "\n",
    "根据上面的函数代码, 你现在可以构建一个非常深的残差网络.\n",
    "下图描述了模型框架的细节, 其中 \"ID BLOCK\" 代表 \"Identity block\", \"ID BLOCK x3\" 代码连续的3个\"Identity block\".\n",
    "\n",
    "<img src=\"images/resnet_kiank.png\" width=1200>\n",
    "\n",
    "该 ResNet-50 模型的细节如下:\n",
    "- 对输入进行 p = (3,3) 的 Zero-padding\n",
    "- Stage 1:\n",
    "    - 64 个 (7,7) 的滤波器, 步长为 (2,2) 进行 Conv2D.\n",
    "    - 在 'channels' 轴上进行 BatchNorm.\n",
    "    - 使用一个 (3,3) 的窗口, 步长为 (2,2) 进行 MaxPooling.\n",
    "- Stage 2:\n",
    "    - 1 个 convolutional block, 其中三组滤波器的尺寸分别为 [64,64,256], \"f\" 为 3, \"s\" 为 1.\n",
    "    - 2 个 identity block, 其中三组滤波器的尺寸分别为 [64,64,256], \"f\" 为 3.\n",
    "- Stage 3:\n",
    "    - 1 个 convolutional block, 其中三组滤波器的尺寸分别为 [128,128,512], \"f\" 为 3, \"s\" 为 2.\n",
    "    - 3 个 identity block, 其中三组滤波器的尺寸分别为 [128,128,512], \"f\" 为 3.\n",
    "- Stage 4:\n",
    "    - 1 个 convolutional block, 其中三组滤波器的尺寸分别为 [256, 256, 1024], \"f\" 为 3, \"s\" 为 2.\n",
    "    - 5 个 identity block, 其中三组滤波器的尺寸分别为 [256, 256, 1024], \"f\" 为 3.\n",
    "- Stage 5:\n",
    "    - 1 个 convolutional block, 其中三组滤波器的尺寸分别为 [512, 512, 2048], \"f\" 为 3, \"s\" 为 2.\n",
    "    - 2 个 identity block, 其中三组滤波器的尺寸分别为 [512, 512, 2048], \"f\" 为 3.\n",
    "- 2D 的 Average Pooling, 使用的窗口形状为 (2,2).\n",
    "- 'flatten' 层, 无超参数.\n",
    "- 全连接层 (Dense), 使用softmax, 根据分类数指定其最终的神经元个数.\n",
    "\n",
    "    \n",
    "<a name='ex-3'></a>      \n",
    "#### 练习 3 - ResNet50\n",
    "    \n",
    "实现上图中所示的 ResNet 模型."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-10dc95a4cf6275b9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function:\n",
    "    Stage-wise implementation of the architecture of the popular ResNet50:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> FLATTEN -> DENSE\n",
    "Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "\"\"\"\n",
    "def ResNet50(input_shape = (64, 64, 3), classes = 6):\n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    \n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides = (2, 2), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], s = 1)\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "\n",
    "    ### START CODE HERE\n",
    "    ## Stage 3 (≈4 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [128,128,512], s = 2)\n",
    "    X = identity_block(X, 3,  [128,128,512])\n",
    "    X = identity_block(X, 3,  [128,128,512])\n",
    "    X = identity_block(X, 3,  [128,128,512])\n",
    "    ## Stage 4 (≈6 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], s = 2)\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    ## Stage 5 (≈3 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], s = 2)\n",
    "    X = identity_block(X, 3, [512, 512, 2048])\n",
    "    X = identity_block(X, 3, [512, 512, 2048])\n",
    "    ## AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
    "    X = AveragePooling2D((2, 2))(X)\n",
    "    ### END CODE HERE\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行下面的代码来构建模型图结构. 如果你的编码有误, 通过运行后面的代码 `model.fit(...)` 并校验准确率可进行判断."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 64, 64, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 70, 70, 3)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 32, 32, 64)   9472        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 32, 32, 64)   256         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 32, 32, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 15, 15, 64)   0           activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 15, 15, 64)   4160        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 15, 15, 64)   256         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 15, 15, 64)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 15, 15, 64)   36928       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 15, 15, 64)   256         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 15, 15, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 15, 15, 256)  16640       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 15, 15, 256)  16640       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 15, 15, 256)  1024        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 15, 15, 256)  1024        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 15, 15, 256)  0           batch_normalization_26[0][0]     \n",
      "                                                                 batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 15, 15, 256)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 15, 15, 64)   16448       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 15, 15, 64)   256         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 15, 15, 64)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 15, 15, 64)   36928       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 15, 15, 64)   256         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 15, 15, 64)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 15, 15, 256)  16640       activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 15, 15, 256)  1024        conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 15, 15, 256)  0           activation_23[0][0]              \n",
      "                                                                 batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 15, 15, 256)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 15, 15, 64)   16448       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 15, 15, 64)   256         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 15, 15, 64)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 15, 15, 64)   36928       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 15, 15, 64)   256         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 15, 15, 64)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 15, 15, 256)  16640       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 15, 15, 256)  1024        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 15, 15, 256)  0           activation_26[0][0]              \n",
      "                                                                 batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 15, 15, 256)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 8, 8, 128)    32896       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 8, 8, 128)    512         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 8, 8, 128)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 8, 8, 128)    147584      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 8, 8, 128)    512         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 8, 8, 128)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 8, 8, 512)    66048       activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 8, 8, 512)    131584      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 8, 8, 512)    2048        conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 8, 8, 512)    2048        conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 8, 8, 512)    0           batch_normalization_36[0][0]     \n",
      "                                                                 batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 8, 8, 512)    0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 8, 8, 128)    65664       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 8, 8, 128)    512         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 8, 8, 128)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 8, 8, 128)    147584      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 8, 8, 128)    512         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 8, 8, 128)    0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 8, 8, 512)    66048       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 8, 8, 512)    2048        conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 8, 8, 512)    0           activation_32[0][0]              \n",
      "                                                                 batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 8, 8, 512)    0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 8, 8, 128)    65664       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 8, 8, 128)    512         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 8, 8, 128)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 8, 8, 128)    147584      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 8, 8, 128)    512         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 8, 8, 128)    0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 8, 8, 512)    66048       activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 8, 8, 512)    2048        conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 8, 8, 512)    0           activation_35[0][0]              \n",
      "                                                                 batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 8, 8, 512)    0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 8, 8, 128)    65664       activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 8, 8, 128)    512         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 8, 8, 128)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 8, 8, 128)    147584      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 8, 8, 128)    512         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 8, 8, 128)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 8, 8, 512)    66048       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 8, 8, 512)    2048        conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 8, 8, 512)    0           activation_38[0][0]              \n",
      "                                                                 batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 8, 8, 512)    0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 4, 4, 256)    131328      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 4, 4, 256)    1024        conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 4, 4, 256)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 4, 4, 256)    590080      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 4, 4, 256)    1024        conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 4, 4, 256)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 4, 4, 1024)   263168      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 4, 4, 1024)   525312      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 4, 4, 1024)   4096        conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 4, 4, 1024)   4096        conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 4, 4, 1024)   0           batch_normalization_49[0][0]     \n",
      "                                                                 batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 4, 4, 1024)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 4, 4, 256)    262400      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 4, 4, 256)    1024        conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 4, 4, 256)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 4, 4, 256)    590080      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 4, 4, 256)    1024        conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 4, 4, 256)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 4, 4, 1024)   263168      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 4, 4, 1024)   4096        conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 4, 4, 1024)   0           activation_44[0][0]              \n",
      "                                                                 batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 4, 4, 1024)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 4, 4, 256)    262400      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 4, 4, 256)    1024        conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 4, 4, 256)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 4, 4, 256)    590080      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 4, 4, 256)    1024        conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 4, 4, 256)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 4, 4, 1024)   263168      activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 4, 4, 1024)   4096        conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 4, 4, 1024)   0           activation_47[0][0]              \n",
      "                                                                 batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 4, 4, 1024)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 4, 4, 256)    262400      activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 4, 4, 256)    1024        conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 4, 4, 256)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 4, 4, 256)    590080      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 4, 4, 256)    1024        conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 4, 4, 256)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 4, 4, 1024)   263168      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 4, 4, 1024)   4096        conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 4, 4, 1024)   0           activation_50[0][0]              \n",
      "                                                                 batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 4, 4, 1024)   0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 4, 4, 256)    262400      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 4, 4, 256)    1024        conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 4, 4, 256)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 4, 4, 256)    590080      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 4, 4, 256)    1024        conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 4, 4, 256)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 4, 4, 1024)   263168      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 4, 4, 1024)   4096        conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 4, 4, 1024)   0           activation_53[0][0]              \n",
      "                                                                 batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 4, 4, 1024)   0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 4, 4, 256)    262400      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 4, 4, 256)    1024        conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 4, 4, 256)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 4, 4, 256)    590080      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 4, 4, 256)    1024        conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 4, 4, 256)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 4, 4, 1024)   263168      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 4, 4, 1024)   4096        conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 4, 4, 1024)   0           activation_56[0][0]              \n",
      "                                                                 batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 4, 4, 1024)   0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 2, 2, 512)    524800      activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 2, 2, 512)    2048        conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 2, 2, 512)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 2, 2, 512)    2359808     activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 2, 2, 512)    2048        conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 2, 2, 512)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 2, 2, 2048)   1050624     activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 2, 2, 2048)   2099200     activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 2, 2, 2048)   8192        conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 2, 2, 2048)   8192        conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 2, 2, 2048)   0           batch_normalization_68[0][0]     \n",
      "                                                                 batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 2, 2, 2048)   0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 2, 2, 512)    1049088     activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 2, 2, 512)    2048        conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 2, 2, 512)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 2, 2, 512)    2359808     activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 2, 2, 512)    2048        conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 2, 2, 512)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 2, 2, 2048)   1050624     activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 2, 2, 2048)   8192        conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 2, 2, 2048)   0           activation_62[0][0]              \n",
      "                                                                 batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 2, 2, 2048)   0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 2, 2, 512)    1049088     activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 2, 2, 512)    2048        conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 2, 2, 512)    0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 2, 2, 512)    2359808     activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 2, 2, 512)    2048        conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 2, 2, 512)    0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 2, 2, 2048)   1050624     activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 2, 2, 2048)   8192        conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 2, 2, 2048)   0           activation_65[0][0]              \n",
      "                                                                 batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 2, 2, 2048)   0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 1, 1, 2048)   0           activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 6)            12294       flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,600,006\n",
      "Trainable params: 23,546,886\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50(input_shape = (64, 64, 3), classes = 6)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-866b891ec47ccb7b",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mAll tests passed!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from lib_outputs import ResNet50_summary\n",
    "\n",
    "model = ResNet50(input_shape = (64, 64, 3), classes = 6)\n",
    "\n",
    "comparator(summary(model), ResNet50_summary)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在训练之前, 首先需要通过compile来配置学习过程."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来载入数据库并进行训练! 数据库可视化如下:\n",
    "<img src=\"images/signs_data_kiank.png\" width=1000>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 1080\n",
      "number of test examples = 120\n",
      "X_train shape: (1080, 64, 64, 3)\n",
      "Y_train shape: (1080, 6)\n",
      "X_test shape: (120, 64, 64, 3)\n",
      "Y_test shape: (120, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
    "\n",
    "# Normalize image vectors\n",
    "X_train = X_train_orig / 255.\n",
    "X_test = X_test_orig / 255.\n",
    "\n",
    "# Convert training and test labels to one hot matrices\n",
    "Y_train = convert_to_one_hot(Y_train_orig, 6).T\n",
    "Y_test = convert_to_one_hot(Y_test_orig, 6).T\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行下面的代码来训练你的模型, 其中 epochs 设置为10, batch size 为 32. 如果采用 GPU, 2分钟以内应该可以完成训练."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "34/34 [==============================] - 47s 1s/step - loss: 1.8382 - accuracy: 0.5148\n",
      "Epoch 2/5\n",
      "34/34 [==============================] - 54s 2s/step - loss: 0.7951 - accuracy: 0.7556\n",
      "Epoch 3/5\n",
      "34/34 [==============================] - 50s 1s/step - loss: 0.2812 - accuracy: 0.8954\n",
      "Epoch 4/5\n",
      "34/34 [==============================] - 54s 2s/step - loss: 0.3020 - accuracy: 0.8954\n",
      "Epoch 5/5\n",
      "34/34 [==============================] - 54s 2s/step - loss: 0.5331 - accuracy: 0.8259\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x270b277dc10>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs = 5, batch_size = 32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "```\n",
    "Epoch 1/10\n",
    "34/34 [==============================] - 1s 34ms/step - loss: 1.9241 - accuracy: 0.4620\n",
    "Epoch 2/10\n",
    "34/34 [==============================] - 2s 57ms/step - loss: 0.6403 - accuracy: 0.7898\n",
    "Epoch 3/10\n",
    "34/34 [==============================] - 1s 24ms/step - loss: 0.3744 - accuracy: 0.8731\n",
    "Epoch 4/10\n",
    "34/34 [==============================] - 2s 44ms/step - loss: 0.2220 - accuracy: 0.9231\n",
    "Epoch 5/10\n",
    "34/34 [==============================] - 2s 57ms/step - loss: 0.1333 - accuracy: 0.9583\n",
    "Epoch 6/10\n",
    "34/34 [==============================] - 2s 52ms/step - loss: 0.2243 - accuracy: 0.9444\n",
    "Epoch 7/10\n",
    "34/34 [==============================] - 2s 48ms/step - loss: 0.2913 - accuracy: 0.9102\n",
    "Epoch 8/10\n",
    "34/34 [==============================] - 1s 30ms/step - loss: 0.2269 - accuracy: 0.9306\n",
    "Epoch 9/10\n",
    "34/34 [==============================] - 2s 46ms/step - loss: 0.1113 - accuracy: 0.9630\n",
    "Epoch 10/10\n",
    "34/34 [==============================] - 2s 57ms/step - loss: 0.0709 - accuracy: 0.9778\n",
    "```\n",
    "\n",
    "如果上述accuracy数值无法匹配, 不用担心. 重要的是loss一直在下降, 在前 5 个 epochs 上准确率一直在提升."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们看看训练所得模型在测试集上的效果."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 276ms/step - loss: 0.3530 - accuracy: 0.8667\n",
      "Loss = 0.3529733419418335\n",
      "Test Accuracy = 0.8666666746139526\n"
     ]
    }
   ],
   "source": [
    "preds = model.evaluate(X_test, Y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <b>Test Accuracy</b>\n",
    "        </td>\n",
    "        <td>\n",
    "           >0.80\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你继续训练到20轮, 会得到性能更好的模型. 但是在CPU上可能需要花费超过1个小时.\n",
    "\n",
    "你可以载入另外一个已训练好的模型(请通过QQ等方式获取resnet50.h5文件), 并在测试集上进行测试!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: resnet50.h5/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pre_trained_model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mload_model(\u001b[39m'\u001b[39;49m\u001b[39mresnet50.h5\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32md:\\origin\\software\\program\\Anaconda\\envs\\MyJupterWorkerSpace\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py:186\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    184\u001b[0m   filepath \u001b[39m=\u001b[39m path_to_string(filepath)\n\u001b[0;32m    185\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(filepath, six\u001b[39m.\u001b[39mstring_types):\n\u001b[1;32m--> 186\u001b[0m     loader_impl\u001b[39m.\u001b[39;49mparse_saved_model(filepath)\n\u001b[0;32m    187\u001b[0m     \u001b[39mreturn\u001b[39;00m saved_model_load\u001b[39m.\u001b[39mload(filepath, \u001b[39mcompile\u001b[39m, options)\n\u001b[0;32m    189\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\n\u001b[0;32m    190\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mUnable to load model. Filepath is not an hdf5 file (or h5py is not \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    191\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mavailable) or SavedModel.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32md:\\origin\\software\\program\\Anaconda\\envs\\MyJupterWorkerSpace\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py:110\u001b[0m, in \u001b[0;36mparse_saved_model\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot parse file \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (path_to_pbtxt, \u001b[39mstr\u001b[39m(e)))\n\u001b[0;32m    109\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 110\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mSavedModel file does not exist at: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m|\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m}\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m    111\u001b[0m                 (export_dir,\n\u001b[0;32m    112\u001b[0m                  constants\u001b[39m.\u001b[39mSAVED_MODEL_FILENAME_PBTXT,\n\u001b[0;32m    113\u001b[0m                  constants\u001b[39m.\u001b[39mSAVED_MODEL_FILENAME_PB))\n",
      "\u001b[1;31mOSError\u001b[0m: SavedModel file does not exist at: resnet50.h5/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "pre_trained_model = tf.keras.models.load_model('resnet50.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pre_trained_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m preds \u001b[39m=\u001b[39m pre_trained_model\u001b[39m.\u001b[39mevaluate(X_test, Y_test)\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mLoss = \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(preds[\u001b[39m0\u001b[39m]))\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mTest Accuracy = \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(preds[\u001b[39m1\u001b[39m]))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pre_trained_model' is not defined"
     ]
    }
   ],
   "source": [
    "preds = pre_trained_model.evaluate(X_test, Y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations** on finishing this assignment! You've now implemented a state-of-the-art image classification system! Woo hoo! \n",
    "\n",
    "ResNet50 is a powerful model for image classification when it's trained for an adequate number of iterations. Hopefully, from this point, you can use what you've learned and apply it to your own classification problem to perform state-of-the-art accuracy."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'blue'>\n",
    "\n",
    "**What you should remember**:\n",
    "\n",
    "- Very deep \"plain\" networks don't work in practice because vanishing gradients make them hard to train.  \n",
    "- Skip connections help address the Vanishing Gradient problem. They also make it easy for a ResNet block to learn an identity function. \n",
    "- There are two main types of blocks: The **identity block** and the **convolutional block**. \n",
    "- Very deep Residual Networks are built by stacking these blocks together."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='5'></a>  \n",
    "## 5 - Test on Your Own Image (Optional/Ungraded)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish, you can also take a picture of your own hand and see the output of the model. To do this:\n",
    "    1. Click on \"File\" in the upper bar of this notebook, then click \"Open\" to go on your Coursera Hub.\n",
    "    2. Add your image to this Jupyter Notebook's directory, in the \"images\" folder\n",
    "    3. Write your image's name in the following code\n",
    "    4. Run the code and check if the algorithm is right! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input image shape: (1, 64, 64, 3)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pre_trained_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mInput image shape:\u001b[39m\u001b[39m'\u001b[39m, x\u001b[39m.\u001b[39mshape)\n\u001b[0;32m      7\u001b[0m imshow(img)\n\u001b[1;32m----> 8\u001b[0m prediction \u001b[39m=\u001b[39m pre_trained_model\u001b[39m.\u001b[39mpredict(x)\n\u001b[0;32m      9\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mClass prediction vector [p(0), p(1), p(2), p(3), p(4), p(5)] = \u001b[39m\u001b[39m\"\u001b[39m, prediction)\n\u001b[0;32m     10\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mClass:\u001b[39m\u001b[39m\"\u001b[39m, np\u001b[39m.\u001b[39margmax(prediction))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pre_trained_model' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_path = 'images/my_image.jpg'\n",
    "img = image.load_img(img_path, target_size=(64, 64))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = x/255.0\n",
    "print('Input image shape:', x.shape)\n",
    "imshow(img)\n",
    "prediction = pre_trained_model.predict(x)\n",
    "print(\"Class prediction vector [p(0), p(1), p(2), p(3), p(4), p(5)] = \", prediction)\n",
    "print(\"Class:\", np.argmax(prediction))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also print a summary of your model by running the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pre_trained_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pre_trained_model\u001b[39m.\u001b[39msummary()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pre_trained_model' is not defined"
     ]
    }
   ],
   "source": [
    "pre_trained_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='6'></a>  \n",
    "## 6 - Bibliography\n",
    "\n",
    "This notebook presents the ResNet algorithm from He et al. (2015). The implementation here also took significant inspiration and follows the structure given in the GitHub repository of Francois Chollet: \n",
    "\n",
    "- Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun - [Deep Residual Learning for Image Recognition (2015)](https://arxiv.org/abs/1512.03385)\n",
    "- Francois Chollet's GitHub repository: https://github.com/fchollet/deep-learning-models/blob/master/resnet50.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
